{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25c72f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import os\n",
    "from os import listdir\n",
    "from scipy.io import loadmat\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44d3c15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/1/', '/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/2/', '/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/3/']\n",
      "8 9\n",
      "{0: (0, 3), 1: (0, 4), 2: (0, 5), 3: (0, 2), 4: (0, 6), 5: (1, 0), 6: (1, 1), 7: (1, 2), 8: (1, 3), 9: (1, 4), 10: (1, 5), 11: (1, 6), 12: (1, 7), 13: (1, 8), 14: (2, 0), 15: (2, 1), 16: (2, 2), 17: (2, 3), 18: (2, 4), 19: (2, 5), 20: (2, 6), 21: (2, 7), 22: (2, 8), 23: (3, 0), 24: (3, 1), 25: (3, 2), 26: (3, 3), 27: (3, 4), 28: (3, 5), 29: (3, 6), 30: (3, 7), 31: (3, 8), 32: (4, 0), 33: (4, 1), 34: (4, 2), 35: (4, 3), 36: (4, 4), 37: (4, 5), 38: (4, 6), 39: (4, 7), 40: (4, 8), 41: (5, 0), 42: (5, 1), 43: (5, 2), 44: (5, 3), 45: (5, 4), 46: (5, 5), 47: (5, 6), 48: (5, 7), 49: (5, 8), 50: (6, 1), 51: (6, 2), 52: (6, 3), 53: (6, 4), 54: (6, 5), 55: (6, 6), 56: (6, 7), 57: (7, 2), 58: (7, 3), 59: (7, 4), 60: (7, 5), 61: (7, 6)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = \"/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/1/\"\n",
    "directories = [\"/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/{}/\".format(i+1) for i in range(3)] \n",
    "print(directories)\n",
    "channel_coords = [['0', '0', 'AF3', 'FP1', 'FPZ', 'FP2', 'AF4', '0', '0'], ['F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8'], ['FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8'], ['T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8'], ['TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8'], ['P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8'], ['0', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', '0'], ['0', '0', 'CB1', 'O1', 'OZ', 'O2', 'CB2', '0', '0']]\n",
    "\n",
    "channel_list = ['FP1', 'FPZ', 'FP2', 'AF3', 'AF4', 'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8', 'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8', 'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8', 'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO5', 'PO3', 'POZ', 'PO4', 'PO6', 'PO8', 'CB1', 'O1', 'OZ', 'O2', 'CB2']\n",
    "print(len(channel_coords), len(channel_coords[0]))\n",
    "coord_dict = {}\n",
    "for n in range(len(channel_list)):\n",
    "    for i, l in enumerate(channel_coords):\n",
    "        for j, x in enumerate(l):\n",
    "            if (channel_list[n] == x):\n",
    "                coord_dict[n] = (i,j)\n",
    "print(coord_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0433bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/1/\n",
      "/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/2/\n",
      "/home/work/HCOH/archive/seed_iv/eeg_feature_smooth/3/\n",
      "(3, 15, 24, 4, 8, 9, 5, 64)\n"
     ]
    }
   ],
   "source": [
    "n = 24\n",
    "perSample = ['de_movingAve', 'de_LDS', 'psd_movingAve', 'psd_LDS']\n",
    "array = np.zeros(shape=(len(directories),len(os.listdir(directories[0])), n, 4, 8, 9, 5, 64)) # features = 4 datatypes*(8 x 9 eeg channel locs)*5 frequency bands*64 timestamps(zero padded) // trials = (3 sessions) x 15 people x 24 labels \n",
    "li = []\n",
    "for h, dire in enumerate(directories):\n",
    "    print(dire)\n",
    "    data = [loadmat(dire + file) for file in os.listdir(dire)]\n",
    "    for i, bigsample in enumerate(data):\n",
    "        for j in range(n):\n",
    "            for k, key in enumerate(perSample):\n",
    "                sample = np.transpose(np.array(bigsample[key + str(j+1)]), (0,2,1))\n",
    "                sample = np.pad(sample, [(0,0), (0,0), (0, 64-sample.shape[2])])\n",
    "                for l, channel in enumerate(sample):\n",
    "                    array[h][i][j][k][coord_dict[l][0]][coord_dict[l][1]] = channel\n",
    "\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59f222b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 4, 8, 9, 5, 64)\n",
      "(3, 15, 24, 64, 8, 9, 5)\n"
     ]
    }
   ],
   "source": [
    "_X = array.reshape(np.prod(array.shape[0:3]), *array.shape[3:])\n",
    "print(_X.shape)\n",
    "X_loso = array[:,:,:,1,:,:,]\n",
    "X_loso = np.transpose(X_loso, (0,1,2,6,3,4,5))\n",
    "print(X_loso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e81af5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080,)\n",
      "(3, 15, 24)\n"
     ]
    }
   ],
   "source": [
    "session1_label = [1,2,3,0,2,0,0,1,0,1,2,1,1,1,2,3,2,2,3,3,0,3,0,3]\n",
    "session2_label = [2,1,3,0,0,2,0,2,3,3,2,3,2,0,1,1,2,1,0,3,0,1,3,1]\n",
    "session3_label = [1,2,2,1,3,3,3,1,1,2,1,0,2,3,3,0,2,3,0,0,2,0,1,0]\n",
    "labels = {0: 'neutral', 1: 'sad', 2: 'fear', 3: 'happy'}\n",
    "\n",
    "y = np.array(session1_label * 15 + session2_label * 15 + session3_label * 15)\n",
    "\n",
    "print(y.shape)\n",
    "y_loso = np.reshape(y, (3,15,24))\n",
    "print(y_loso.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eab3279a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 4, 8, 9, 5)\n",
      "(1080, 64, 1440)\n"
     ]
    }
   ],
   "source": [
    "X = _X.transpose(0, 5, 1,2,3,4)\n",
    "print(X.shape)\n",
    "X = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38866cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05c83bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = pd.get_dummies(y_train).values\n",
    "y_test_onehot = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d08a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.astype('float32')\n",
    "y_train_onehot = y_train_onehot.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test_onehot = y_test_onehot.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8300d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv1D , LSTM\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da78fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 16:16:14.391699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 37742 MB memory:  -> device: 0, name: CUDA GPU, pci bus id: 0000:4c:00.0, compute capability: 8.0\n",
      "2024-07-15 16:16:14.393991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1883] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38284 MB memory:  -> device: 1, name: CUDA GPU, pci bus id: 0000:88:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-15 16:16:16.947370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-07-15 16:16:18.066697: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2638212c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-15 16:16:18.066749: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): CUDA GPU, Compute Capability 8.0\n",
      "2024-07-15 16:16:18.066758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): CUDA GPU, Compute Capability 8.0\n",
      "2024-07-15 16:16:18.072451: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-15 16:16:18.156466: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729/729 [==============================] - 7s 5ms/step - loss: 1.3859 - accuracy: 0.3032 - val_loss: 1.3524 - val_accuracy: 0.3086\n",
      "Epoch 2/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2703 - accuracy: 0.3992 - val_loss: 1.3400 - val_accuracy: 0.3457\n",
      "Epoch 3/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.2120 - accuracy: 0.4184 - val_loss: 1.3676 - val_accuracy: 0.3457\n",
      "Epoch 4/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1898 - accuracy: 0.4184 - val_loss: 1.3316 - val_accuracy: 0.3457\n",
      "Epoch 5/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2012 - accuracy: 0.3964 - val_loss: 1.3304 - val_accuracy: 0.2222\n",
      "Epoch 6/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1855 - accuracy: 0.4060 - val_loss: 1.2475 - val_accuracy: 0.4321\n",
      "Epoch 7/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1449 - accuracy: 0.4417 - val_loss: 1.2297 - val_accuracy: 0.2716\n",
      "Epoch 8/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1355 - accuracy: 0.4568 - val_loss: 1.2218 - val_accuracy: 0.4198\n",
      "Epoch 9/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1103 - accuracy: 0.4527 - val_loss: 1.1688 - val_accuracy: 0.3704\n",
      "Epoch 10/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1152 - accuracy: 0.4486 - val_loss: 1.2451 - val_accuracy: 0.2593\n",
      "Epoch 11/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0942 - accuracy: 0.4801 - val_loss: 1.3087 - val_accuracy: 0.3333\n",
      "Epoch 12/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1033 - accuracy: 0.4705 - val_loss: 1.1598 - val_accuracy: 0.4198\n",
      "Epoch 13/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0850 - accuracy: 0.4925 - val_loss: 1.1874 - val_accuracy: 0.4074\n",
      "Epoch 14/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0842 - accuracy: 0.4815 - val_loss: 1.1773 - val_accuracy: 0.4074\n",
      "Epoch 15/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0574 - accuracy: 0.4815 - val_loss: 1.2233 - val_accuracy: 0.3704\n",
      "Epoch 16/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0682 - accuracy: 0.4829 - val_loss: 1.3588 - val_accuracy: 0.3827\n",
      "Epoch 17/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0529 - accuracy: 0.4993 - val_loss: 1.1466 - val_accuracy: 0.4198\n",
      "Epoch 18/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0589 - accuracy: 0.4883 - val_loss: 1.1454 - val_accuracy: 0.5185\n",
      "Epoch 19/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0372 - accuracy: 0.4925 - val_loss: 1.3151 - val_accuracy: 0.3333\n",
      "Epoch 20/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0238 - accuracy: 0.4979 - val_loss: 1.2054 - val_accuracy: 0.4568\n",
      "Epoch 21/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0116 - accuracy: 0.5034 - val_loss: 1.0943 - val_accuracy: 0.4568\n",
      "Epoch 22/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0347 - accuracy: 0.5089 - val_loss: 1.0889 - val_accuracy: 0.4815\n",
      "Epoch 23/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0012 - accuracy: 0.5240 - val_loss: 1.0905 - val_accuracy: 0.4815\n",
      "Epoch 24/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9876 - accuracy: 0.5336 - val_loss: 1.0979 - val_accuracy: 0.4815\n",
      "Epoch 25/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9665 - accuracy: 0.5528 - val_loss: 1.0739 - val_accuracy: 0.4321\n",
      "Epoch 26/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9620 - accuracy: 0.5679 - val_loss: 1.1607 - val_accuracy: 0.4568\n",
      "Epoch 27/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9643 - accuracy: 0.5583 - val_loss: 1.0411 - val_accuracy: 0.4691\n",
      "Epoch 28/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9246 - accuracy: 0.5624 - val_loss: 1.2073 - val_accuracy: 0.3704\n",
      "Epoch 29/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9534 - accuracy: 0.5460 - val_loss: 1.2477 - val_accuracy: 0.3580\n",
      "Epoch 30/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9130 - accuracy: 0.5720 - val_loss: 1.0832 - val_accuracy: 0.4198\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "Fold 1 - Accuracy: 0.6259, F1 Score: 0.6255\n",
      "Confusion Matrix:\n",
      "[[49 12  0  6]\n",
      " [ 8 51  9  0]\n",
      " [25  5 35  2]\n",
      " [16  4 14 34]]\n",
      "Training fold 2...\n",
      "Epoch 1/30\n",
      "729/729 [==============================] - 5s 5ms/step - loss: 1.3701 - accuracy: 0.3141 - val_loss: 1.2598 - val_accuracy: 0.4815\n",
      "Epoch 2/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.2972 - accuracy: 0.3978 - val_loss: 1.2492 - val_accuracy: 0.3827\n",
      "Epoch 3/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2723 - accuracy: 0.3868 - val_loss: 1.2485 - val_accuracy: 0.4938\n",
      "Epoch 4/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2313 - accuracy: 0.4102 - val_loss: 1.2697 - val_accuracy: 0.4198\n",
      "Epoch 5/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2056 - accuracy: 0.4362 - val_loss: 1.2762 - val_accuracy: 0.4444\n",
      "Epoch 6/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1947 - accuracy: 0.4335 - val_loss: 1.2568 - val_accuracy: 0.4198\n",
      "Epoch 7/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1726 - accuracy: 0.4540 - val_loss: 1.1430 - val_accuracy: 0.4691\n",
      "Epoch 8/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1392 - accuracy: 0.4513 - val_loss: 1.2017 - val_accuracy: 0.4815\n",
      "Epoch 9/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.1224 - accuracy: 0.4527 - val_loss: 1.2792 - val_accuracy: 0.5185\n",
      "Epoch 10/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1142 - accuracy: 0.4883 - val_loss: 1.2433 - val_accuracy: 0.4568\n",
      "Epoch 11/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.1056 - accuracy: 0.4925 - val_loss: 1.1251 - val_accuracy: 0.4568\n",
      "Epoch 12/30\n",
      "729/729 [==============================] - 4s 5ms/step - loss: 1.0954 - accuracy: 0.4787 - val_loss: 1.1628 - val_accuracy: 0.4815\n",
      "Epoch 13/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0657 - accuracy: 0.4993 - val_loss: 1.1392 - val_accuracy: 0.4691\n",
      "Epoch 14/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.0704 - accuracy: 0.4897 - val_loss: 1.1890 - val_accuracy: 0.4074\n",
      "Epoch 15/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0383 - accuracy: 0.5075 - val_loss: 1.1841 - val_accuracy: 0.4321\n",
      "Epoch 16/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0229 - accuracy: 0.4993 - val_loss: 1.1634 - val_accuracy: 0.5062\n",
      "Epoch 17/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0063 - accuracy: 0.5336 - val_loss: 1.0699 - val_accuracy: 0.4198\n",
      "Epoch 18/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9844 - accuracy: 0.5267 - val_loss: 1.0442 - val_accuracy: 0.4938\n",
      "Epoch 19/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9674 - accuracy: 0.5638 - val_loss: 1.0060 - val_accuracy: 0.5185\n",
      "Epoch 20/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9541 - accuracy: 0.5624 - val_loss: 1.0790 - val_accuracy: 0.4938\n",
      "Epoch 21/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9768 - accuracy: 0.5377 - val_loss: 1.1471 - val_accuracy: 0.4568\n",
      "Epoch 22/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 0.9136 - accuracy: 0.5693 - val_loss: 0.9853 - val_accuracy: 0.5185\n",
      "Epoch 23/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9371 - accuracy: 0.5926 - val_loss: 0.9658 - val_accuracy: 0.5185\n",
      "Epoch 24/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9202 - accuracy: 0.5967 - val_loss: 0.9996 - val_accuracy: 0.4321\n",
      "Epoch 25/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.8952 - accuracy: 0.5912 - val_loss: 0.9575 - val_accuracy: 0.5185\n",
      "Epoch 26/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9013 - accuracy: 0.5734 - val_loss: 0.9473 - val_accuracy: 0.4938\n",
      "Epoch 27/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.8567 - accuracy: 0.5995 - val_loss: 0.9324 - val_accuracy: 0.5309\n",
      "Epoch 28/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.8872 - accuracy: 0.5885 - val_loss: 0.9653 - val_accuracy: 0.4444\n",
      "Epoch 29/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.8735 - accuracy: 0.5857 - val_loss: 0.9385 - val_accuracy: 0.5309\n",
      "Epoch 30/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9257 - accuracy: 0.5542 - val_loss: 0.9396 - val_accuracy: 0.4938\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "Fold 2 - Accuracy: 0.5963, F1 Score: 0.5886\n",
      "Confusion Matrix:\n",
      "[[37  4  7 19]\n",
      " [ 2 55  8  3]\n",
      " [ 6 23 25 13]\n",
      " [ 3 11 10 44]]\n",
      "Training fold 3...\n",
      "Epoch 1/30\n",
      "729/729 [==============================] - 5s 5ms/step - loss: 1.3583 - accuracy: 0.3182 - val_loss: 1.3451 - val_accuracy: 0.3951\n",
      "Epoch 2/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2897 - accuracy: 0.3909 - val_loss: 1.2693 - val_accuracy: 0.3457\n",
      "Epoch 3/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2255 - accuracy: 0.4170 - val_loss: 1.4057 - val_accuracy: 0.3333\n",
      "Epoch 4/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1958 - accuracy: 0.4472 - val_loss: 1.2883 - val_accuracy: 0.4198\n",
      "Epoch 5/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1647 - accuracy: 0.4294 - val_loss: 1.1767 - val_accuracy: 0.5062\n",
      "Epoch 6/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1602 - accuracy: 0.4582 - val_loss: 1.1302 - val_accuracy: 0.4691\n",
      "Epoch 7/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1367 - accuracy: 0.4595 - val_loss: 1.2612 - val_accuracy: 0.3333\n",
      "Epoch 8/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1067 - accuracy: 0.4650 - val_loss: 1.1154 - val_accuracy: 0.5309\n",
      "Epoch 9/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1240 - accuracy: 0.4719 - val_loss: 1.0910 - val_accuracy: 0.4815\n",
      "Epoch 10/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0532 - accuracy: 0.5021 - val_loss: 1.1074 - val_accuracy: 0.4815\n",
      "Epoch 11/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0559 - accuracy: 0.4993 - val_loss: 1.1706 - val_accuracy: 0.3827\n",
      "Epoch 12/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0454 - accuracy: 0.4993 - val_loss: 1.1342 - val_accuracy: 0.4444\n",
      "Epoch 13/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0548 - accuracy: 0.4938 - val_loss: 1.0711 - val_accuracy: 0.4444\n",
      "Epoch 14/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0411 - accuracy: 0.5350 - val_loss: 1.1165 - val_accuracy: 0.3827\n",
      "Epoch 15/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.0338 - accuracy: 0.5418 - val_loss: 1.0417 - val_accuracy: 0.5309\n",
      "Epoch 16/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0028 - accuracy: 0.5281 - val_loss: 1.0761 - val_accuracy: 0.4938\n",
      "Epoch 17/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0181 - accuracy: 0.5185 - val_loss: 1.0300 - val_accuracy: 0.4444\n",
      "Epoch 18/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9906 - accuracy: 0.5295 - val_loss: 1.0040 - val_accuracy: 0.3704\n",
      "Epoch 19/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9827 - accuracy: 0.5418 - val_loss: 1.0494 - val_accuracy: 0.4815\n",
      "Epoch 20/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9826 - accuracy: 0.5391 - val_loss: 1.0084 - val_accuracy: 0.4691\n",
      "Epoch 21/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9588 - accuracy: 0.5597 - val_loss: 1.0341 - val_accuracy: 0.4815\n",
      "Epoch 22/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9286 - accuracy: 0.5597 - val_loss: 0.9624 - val_accuracy: 0.5802\n",
      "Epoch 23/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9478 - accuracy: 0.5569 - val_loss: 1.0036 - val_accuracy: 0.4321\n",
      "Epoch 24/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9236 - accuracy: 0.5761 - val_loss: 0.9201 - val_accuracy: 0.4938\n",
      "Epoch 25/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9576 - accuracy: 0.5528 - val_loss: 0.9808 - val_accuracy: 0.4691\n",
      "Epoch 26/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9713 - accuracy: 0.5405 - val_loss: 0.9703 - val_accuracy: 0.4691\n",
      "Epoch 27/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9394 - accuracy: 0.5693 - val_loss: 0.9647 - val_accuracy: 0.4815\n",
      "Epoch 28/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.8888 - accuracy: 0.5885 - val_loss: 0.9825 - val_accuracy: 0.4198\n",
      "Epoch 29/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9066 - accuracy: 0.5830 - val_loss: 0.9581 - val_accuracy: 0.4568\n",
      "Epoch 30/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9051 - accuracy: 0.5789 - val_loss: 0.9318 - val_accuracy: 0.4938\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "Fold 3 - Accuracy: 0.6037, F1 Score: 0.6034\n",
      "Confusion Matrix:\n",
      "[[34 16 11  7]\n",
      " [ 4 37 16 10]\n",
      " [18  4 42  4]\n",
      " [ 0  0 17 50]]\n",
      "Training fold 4...\n",
      "Epoch 1/30\n",
      "729/729 [==============================] - 5s 5ms/step - loss: 1.3749 - accuracy: 0.3100 - val_loss: 1.3269 - val_accuracy: 0.3951\n",
      "Epoch 2/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2945 - accuracy: 0.4033 - val_loss: 1.3126 - val_accuracy: 0.3704\n",
      "Epoch 3/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2463 - accuracy: 0.4266 - val_loss: 1.3602 - val_accuracy: 0.3333\n",
      "Epoch 4/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2094 - accuracy: 0.4294 - val_loss: 1.3829 - val_accuracy: 0.3457\n",
      "Epoch 5/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.2142 - accuracy: 0.4376 - val_loss: 1.2700 - val_accuracy: 0.4444\n",
      "Epoch 6/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1746 - accuracy: 0.4348 - val_loss: 1.2807 - val_accuracy: 0.3457\n",
      "Epoch 7/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1660 - accuracy: 0.4568 - val_loss: 1.2781 - val_accuracy: 0.3704\n",
      "Epoch 8/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1323 - accuracy: 0.4636 - val_loss: 1.2143 - val_accuracy: 0.4198\n",
      "Epoch 9/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1374 - accuracy: 0.4691 - val_loss: 1.2400 - val_accuracy: 0.4074\n",
      "Epoch 10/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.1188 - accuracy: 0.4636 - val_loss: 1.1920 - val_accuracy: 0.4198\n",
      "Epoch 11/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.1004 - accuracy: 0.4883 - val_loss: 1.2821 - val_accuracy: 0.3704\n",
      "Epoch 12/30\n",
      "729/729 [==============================] - 3s 5ms/step - loss: 1.0689 - accuracy: 0.4856 - val_loss: 1.1462 - val_accuracy: 0.4074\n",
      "Epoch 13/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0394 - accuracy: 0.4650 - val_loss: 1.1324 - val_accuracy: 0.4691\n",
      "Epoch 14/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0594 - accuracy: 0.4911 - val_loss: 1.1082 - val_accuracy: 0.4938\n",
      "Epoch 15/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0580 - accuracy: 0.5048 - val_loss: 1.1617 - val_accuracy: 0.3457\n",
      "Epoch 16/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 1.0263 - accuracy: 0.5199 - val_loss: 1.1480 - val_accuracy: 0.3086\n",
      "Epoch 17/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9983 - accuracy: 0.5226 - val_loss: 1.1424 - val_accuracy: 0.3210\n",
      "Epoch 18/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9799 - accuracy: 0.4993 - val_loss: 1.1517 - val_accuracy: 0.3580\n",
      "Epoch 19/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9797 - accuracy: 0.5213 - val_loss: 1.3579 - val_accuracy: 0.3333\n",
      "Epoch 20/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9736 - accuracy: 0.5185 - val_loss: 1.0881 - val_accuracy: 0.4198\n",
      "Epoch 21/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9812 - accuracy: 0.5281 - val_loss: 1.1091 - val_accuracy: 0.4321\n",
      "Epoch 22/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9869 - accuracy: 0.5158 - val_loss: 1.1067 - val_accuracy: 0.3457\n",
      "Epoch 23/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9768 - accuracy: 0.5226 - val_loss: 1.0360 - val_accuracy: 0.5062\n",
      "Epoch 24/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9594 - accuracy: 0.5309 - val_loss: 1.0766 - val_accuracy: 0.4938\n",
      "Epoch 25/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9545 - accuracy: 0.5295 - val_loss: 1.0156 - val_accuracy: 0.4568\n",
      "Epoch 26/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9349 - accuracy: 0.5350 - val_loss: 1.0539 - val_accuracy: 0.4321\n",
      "Epoch 27/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9263 - accuracy: 0.5432 - val_loss: 1.0880 - val_accuracy: 0.4444\n",
      "Epoch 28/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9319 - accuracy: 0.5624 - val_loss: 1.0181 - val_accuracy: 0.4815\n",
      "Epoch 29/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.8978 - accuracy: 0.5734 - val_loss: 1.1664 - val_accuracy: 0.3827\n",
      "Epoch 30/30\n",
      "729/729 [==============================] - 3s 4ms/step - loss: 0.9361 - accuracy: 0.5720 - val_loss: 1.1786 - val_accuracy: 0.4321\n",
      "270/270 [==============================] - 1s 2ms/step\n",
      "Fold 4 - Accuracy: 0.4852, F1 Score: 0.4869\n",
      "Confusion Matrix:\n",
      "[[35 13  3 17]\n",
      " [ 9 27  8 23]\n",
      " [ 8  8 39 13]\n",
      " [ 9  2 26 30]]\n",
      "4-Fold Cross Validation Results:\n",
      "Accuracy: 0.5778 ± 0.0546\n",
      "F1 Score: 0.5761 ± 0.0532\n",
      "Confusion Matrix for Fold 1:\n",
      "[[49 12  0  6]\n",
      " [ 8 51  9  0]\n",
      " [25  5 35  2]\n",
      " [16  4 14 34]]\n",
      "Confusion Matrix for Fold 2:\n",
      "[[37  4  7 19]\n",
      " [ 2 55  8  3]\n",
      " [ 6 23 25 13]\n",
      " [ 3 11 10 44]]\n",
      "Confusion Matrix for Fold 3:\n",
      "[[34 16 11  7]\n",
      " [ 4 37 16 10]\n",
      " [18  4 42  4]\n",
      " [ 0  0 17 50]]\n",
      "Confusion Matrix for Fold 4:\n",
      "[[35 13  3 17]\n",
      " [ 9 27  8 23]\n",
      " [ 8  8 39 13]\n",
      " [ 9  2 26 30]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Flatten, MaxPooling1D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import gc\n",
    "\n",
    "# Seed 설정\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# GPU 메모리 할당 방식 변경\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# 주어진 데이터\n",
    "X = _X.transpose(0, 5, 1, 2, 3, 4)\n",
    "X = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\n",
    "y = y\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y_onehot = to_categorical(y)\n",
    "\n",
    "# KFold 설정\n",
    "kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# KFold 교차 검증 수행\n",
    "fold_no = 1\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    print(f'Training fold {fold_no}...')\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_onehot[train_index], y_onehot[test_index]\n",
    "\n",
    "    # Conv1D와 LSTM 모델 정의\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(n_timesteps, n_features)))  # 필터 수 감소\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(64))  # 유닛 수 감소\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))  # 유닛 수 감소\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    train_epochs = 30\n",
    "    batch_size = 1  # 배치 크기 줄이기\n",
    "    history = model.fit(X_train, y_train, epochs=train_epochs, batch_size=batch_size, verbose=True, validation_split=0.1)\n",
    "\n",
    "    # 예측 및 평가\n",
    "    predy = model.predict(X_test, batch_size=batch_size)\n",
    "    predy = np.argmax(predy, axis=-1)\n",
    "    y_test_labels = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(y_test_labels, predy)\n",
    "    f1 = f1_score(y_test_labels, predy, average='weighted')\n",
    "    cm = confusion_matrix(y_test_labels, predy)\n",
    "\n",
    "    print(f'Fold {fold_no} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "    # GPU 메모리 초기화\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# 최종 결과 출력\n",
    "print('4-Fold Cross Validation Results:')\n",
    "print(f'Accuracy: {np.mean(accuracy_list):.4f} ± {np.std(accuracy_list):.4f}')\n",
    "print(f'F1 Score: {np.mean(f1_list):.4f} ± {np.std(f1_list):.4f}')\n",
    "\n",
    "# 최종 혼동 행렬 출력\n",
    "for i, cm in enumerate(confusion_matrices, 1):\n",
    "    print(f'Confusion Matrix for Fold {i}:\\n{cm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b0ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bca6f06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 64, 4, 8, 9, 5)\n",
      "(1080, 64, 1440)\n"
     ]
    }
   ],
   "source": [
    "X = _X.transpose(0, 5, 1,2,3,4)\n",
    "print(X.shape)\n",
    "X = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b65eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 2s 5ms/step - loss: 242862848.0000 - accuracy: 0.2798 - val_loss: 133995.3750 - val_accuracy: 0.2469\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 167893568.0000 - accuracy: 0.2894 - val_loss: 332945.4688 - val_accuracy: 0.2963\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 268123888.0000 - accuracy: 0.3224 - val_loss: 665852.5625 - val_accuracy: 0.2963\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 142387888.0000 - accuracy: 0.3141 - val_loss: 637777.7500 - val_accuracy: 0.3827\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 21917326.0000 - accuracy: 0.3388 - val_loss: 331172.8438 - val_accuracy: 0.3704\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 13700794.0000 - accuracy: 0.3416 - val_loss: 701762.6875 - val_accuracy: 0.3580\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 223722480.0000 - accuracy: 0.3512 - val_loss: 1068079.6250 - val_accuracy: 0.2716\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 57260468.0000 - accuracy: 0.3141 - val_loss: 889797.3125 - val_accuracy: 0.3333\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 52051924.0000 - accuracy: 0.3169 - val_loss: 593675.0625 - val_accuracy: 0.3333\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 13424325.0000 - accuracy: 0.2977 - val_loss: 432386.7500 - val_accuracy: 0.3086\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 6598866.5000 - accuracy: 0.3772 - val_loss: 164818.9062 - val_accuracy: 0.4074\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 17036692.0000 - accuracy: 0.3827 - val_loss: 425672.0625 - val_accuracy: 0.2963\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 24881376.0000 - accuracy: 0.3457 - val_loss: 270242.3750 - val_accuracy: 0.3580\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 10528340.0000 - accuracy: 0.3690 - val_loss: 148787.5938 - val_accuracy: 0.4444\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 773780.8125 - accuracy: 0.3045 - val_loss: 83166.0469 - val_accuracy: 0.3827\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 708963.9375 - accuracy: 0.2922 - val_loss: 17673.3418 - val_accuracy: 0.2716\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2561828.5000 - accuracy: 0.2963 - val_loss: 38361.0430 - val_accuracy: 0.2469\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3548595.7500 - accuracy: 0.2936 - val_loss: 11265.6455 - val_accuracy: 0.2840\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 781169.9375 - accuracy: 0.2908 - val_loss: 7924.4229 - val_accuracy: 0.2593\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1136028.5000 - accuracy: 0.3059 - val_loss: 5436.2661 - val_accuracy: 0.3086\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1341195.2500 - accuracy: 0.3210 - val_loss: 58053.0977 - val_accuracy: 0.3457\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 423748.6875 - accuracy: 0.3827 - val_loss: 12878.2861 - val_accuracy: 0.3333\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 849471.3750 - accuracy: 0.3347 - val_loss: 778.5771 - val_accuracy: 0.2593\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2919186.5000 - accuracy: 0.3141 - val_loss: 2556.8157 - val_accuracy: 0.2840\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2255883.5000 - accuracy: 0.3224 - val_loss: 7350.0249 - val_accuracy: 0.2840\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 937220.6250 - accuracy: 0.2867 - val_loss: 1.4119 - val_accuracy: 0.2593\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 346899.2188 - accuracy: 0.2949 - val_loss: 1.4039 - val_accuracy: 0.2593\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 561703.3750 - accuracy: 0.2894 - val_loss: 1.3993 - val_accuracy: 0.2593\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1552161.0000 - accuracy: 0.2908 - val_loss: 1.3954 - val_accuracy: 0.2593\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 5958.8164 - accuracy: 0.2922 - val_loss: 1.3928 - val_accuracy: 0.2593\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 4s 11ms/step - loss: 1.3762 - accuracy: 0.3278 - val_loss: 1.2857 - val_accuracy: 0.4691\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.3159 - accuracy: 0.3813 - val_loss: 1.2661 - val_accuracy: 0.4691\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2694 - accuracy: 0.4047 - val_loss: 1.2363 - val_accuracy: 0.4815\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2097 - accuracy: 0.4074 - val_loss: 1.1915 - val_accuracy: 0.4815\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1898 - accuracy: 0.4115 - val_loss: 1.2395 - val_accuracy: 0.4568\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1489 - accuracy: 0.4458 - val_loss: 1.2230 - val_accuracy: 0.4321\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1051 - accuracy: 0.4691 - val_loss: 1.1680 - val_accuracy: 0.4691\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1187 - accuracy: 0.4636 - val_loss: 1.1404 - val_accuracy: 0.5062\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0737 - accuracy: 0.5075 - val_loss: 1.1364 - val_accuracy: 0.4938\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0821 - accuracy: 0.4733 - val_loss: 1.1431 - val_accuracy: 0.3951\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0607 - accuracy: 0.5062 - val_loss: 1.1821 - val_accuracy: 0.3827\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0298 - accuracy: 0.5075 - val_loss: 1.1376 - val_accuracy: 0.3951\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0446 - accuracy: 0.5158 - val_loss: 1.1538 - val_accuracy: 0.4321\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0237 - accuracy: 0.4993 - val_loss: 1.1144 - val_accuracy: 0.4321\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9905 - accuracy: 0.5322 - val_loss: 1.1564 - val_accuracy: 0.3951\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9667 - accuracy: 0.5432 - val_loss: 1.1353 - val_accuracy: 0.4444\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9700 - accuracy: 0.5460 - val_loss: 1.1918 - val_accuracy: 0.4074\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9841 - accuracy: 0.5309 - val_loss: 1.1400 - val_accuracy: 0.4198\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9288 - accuracy: 0.5830 - val_loss: 1.2127 - val_accuracy: 0.3951\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9167 - accuracy: 0.5638 - val_loss: 1.1622 - val_accuracy: 0.4691\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9235 - accuracy: 0.5844 - val_loss: 1.1566 - val_accuracy: 0.4444\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8845 - accuracy: 0.5981 - val_loss: 1.2151 - val_accuracy: 0.4444\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8950 - accuracy: 0.5940 - val_loss: 1.2083 - val_accuracy: 0.5185\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9094 - accuracy: 0.5802 - val_loss: 1.2389 - val_accuracy: 0.4568\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8807 - accuracy: 0.6145 - val_loss: 1.2208 - val_accuracy: 0.4815\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8462 - accuracy: 0.6104 - val_loss: 1.2243 - val_accuracy: 0.4815\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8018 - accuracy: 0.6529 - val_loss: 1.2545 - val_accuracy: 0.5432\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8485 - accuracy: 0.6049 - val_loss: 1.2921 - val_accuracy: 0.4691\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8269 - accuracy: 0.6379 - val_loss: 1.3821 - val_accuracy: 0.5185\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8062 - accuracy: 0.6392 - val_loss: 1.2581 - val_accuracy: 0.5432\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 8ms/step - loss: 1.4548 - accuracy: 0.3457 - val_loss: 1.2473 - val_accuracy: 0.5309\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.3503 - accuracy: 0.3525 - val_loss: 1.2531 - val_accuracy: 0.4691\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2790 - accuracy: 0.3923 - val_loss: 1.2237 - val_accuracy: 0.4568\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2721 - accuracy: 0.3937 - val_loss: 1.2154 - val_accuracy: 0.4198\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2390 - accuracy: 0.4060 - val_loss: 1.2017 - val_accuracy: 0.5185\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1918 - accuracy: 0.4376 - val_loss: 1.2737 - val_accuracy: 0.4074\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1553 - accuracy: 0.4417 - val_loss: 1.1470 - val_accuracy: 0.4444\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0842 - accuracy: 0.4705 - val_loss: 1.0343 - val_accuracy: 0.5556\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0563 - accuracy: 0.4856 - val_loss: 0.9817 - val_accuracy: 0.5062\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0522 - accuracy: 0.4787 - val_loss: 0.9580 - val_accuracy: 0.6049\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9739 - accuracy: 0.5048 - val_loss: 0.9103 - val_accuracy: 0.5185\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9222 - accuracy: 0.5267 - val_loss: 0.8776 - val_accuracy: 0.6049\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9032 - accuracy: 0.5610 - val_loss: 0.8594 - val_accuracy: 0.5926\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9051 - accuracy: 0.5336 - val_loss: 0.8519 - val_accuracy: 0.5185\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 5ms/step - loss: 0.8681 - accuracy: 0.5844 - val_loss: 0.8292 - val_accuracy: 0.6173\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8868 - accuracy: 0.5556 - val_loss: 0.8045 - val_accuracy: 0.6296\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8768 - accuracy: 0.5830 - val_loss: 0.8279 - val_accuracy: 0.6173\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8817 - accuracy: 0.5405 - val_loss: 0.7919 - val_accuracy: 0.5309\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8693 - accuracy: 0.5789 - val_loss: 0.7791 - val_accuracy: 0.6049\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8454 - accuracy: 0.5501 - val_loss: 0.7768 - val_accuracy: 0.6296\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8381 - accuracy: 0.5583 - val_loss: 0.7994 - val_accuracy: 0.5679\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8244 - accuracy: 0.5665 - val_loss: 0.7757 - val_accuracy: 0.5926\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8342 - accuracy: 0.5679 - val_loss: 0.7339 - val_accuracy: 0.6420\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8180 - accuracy: 0.5844 - val_loss: 0.7496 - val_accuracy: 0.5309\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8172 - accuracy: 0.5693 - val_loss: 0.7178 - val_accuracy: 0.6296\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8126 - accuracy: 0.5802 - val_loss: 0.7863 - val_accuracy: 0.5062\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8113 - accuracy: 0.5720 - val_loss: 0.7639 - val_accuracy: 0.5679\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8006 - accuracy: 0.5789 - val_loss: 0.7694 - val_accuracy: 0.5802\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8037 - accuracy: 0.6077 - val_loss: 0.7762 - val_accuracy: 0.5432\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8037 - accuracy: 0.5761 - val_loss: 0.7370 - val_accuracy: 0.6296\n",
      "68/68 [==============================] - 0s 2ms/step\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "Fold 1 - CNN Accuracy: 0.2333, CNN F1 Score: 0.0987\n",
      "Fold 1 - LSTM Accuracy: 0.4741, LSTM F1 Score: 0.4582\n",
      "Fold 1 - Hybrid Accuracy: 0.5815, Hybrid F1 Score: 0.5660\n",
      "Training fold 2...\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 2s 4ms/step - loss: 137249744.0000 - accuracy: 0.2853 - val_loss: 84048.6953 - val_accuracy: 0.2716\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 93827128.0000 - accuracy: 0.3045 - val_loss: 18879.2676 - val_accuracy: 0.2840\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 72930872.0000 - accuracy: 0.3059 - val_loss: 11488.6162 - val_accuracy: 0.3827\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 36100940.0000 - accuracy: 0.3580 - val_loss: 3181.9854 - val_accuracy: 0.2716\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 19026990.0000 - accuracy: 0.3471 - val_loss: 5973.5752 - val_accuracy: 0.3333\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 19685764.0000 - accuracy: 0.3676 - val_loss: 12931.4170 - val_accuracy: 0.4321\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 13519748.0000 - accuracy: 0.3923 - val_loss: 538.3915 - val_accuracy: 0.4321\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 12794117.0000 - accuracy: 0.4252 - val_loss: 3509.3047 - val_accuracy: 0.3704\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1212666.2500 - accuracy: 0.3772 - val_loss: 1128.7461 - val_accuracy: 0.3827\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2236874.0000 - accuracy: 0.4033 - val_loss: 1.2707 - val_accuracy: 0.3827\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3689368.0000 - accuracy: 0.3855 - val_loss: 228.1042 - val_accuracy: 0.4198\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 158809.4531 - accuracy: 0.3992 - val_loss: 3.7186 - val_accuracy: 0.4815\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2610024.2500 - accuracy: 0.4431 - val_loss: 43.7995 - val_accuracy: 0.4444\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 27200.0078 - accuracy: 0.4225 - val_loss: 1.2685 - val_accuracy: 0.4691\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1834789.6250 - accuracy: 0.4088 - val_loss: 1.2623 - val_accuracy: 0.4691\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 429136.6875 - accuracy: 0.4184 - val_loss: 1.2596 - val_accuracy: 0.4444\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1386772.2500 - accuracy: 0.4211 - val_loss: 1.2695 - val_accuracy: 0.4444\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 467624.8750 - accuracy: 0.4335 - val_loss: 393.5269 - val_accuracy: 0.4321\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 177989.8125 - accuracy: 0.4294 - val_loss: 1.2614 - val_accuracy: 0.4691\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 328507.8750 - accuracy: 0.4252 - val_loss: 1.2629 - val_accuracy: 0.4074\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 19773872.0000 - accuracy: 0.4266 - val_loss: 1.2538 - val_accuracy: 0.4444\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2846716.2500 - accuracy: 0.4321 - val_loss: 1.2477 - val_accuracy: 0.4444\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 118100.9297 - accuracy: 0.4527 - val_loss: 1.2463 - val_accuracy: 0.4691\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 974.9384 - accuracy: 0.4335 - val_loss: 1.2504 - val_accuracy: 0.4691\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 92367.2656 - accuracy: 0.4362 - val_loss: 1.2476 - val_accuracy: 0.4198\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 748310.8125 - accuracy: 0.4198 - val_loss: 1.2509 - val_accuracy: 0.4321\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 65578.9375 - accuracy: 0.4225 - val_loss: 1.2465 - val_accuracy: 0.4691\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 171038.7500 - accuracy: 0.4486 - val_loss: 1.2414 - val_accuracy: 0.4444\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3972906.2500 - accuracy: 0.4554 - val_loss: 1.2433 - val_accuracy: 0.4444\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 170310.1406 - accuracy: 0.4294 - val_loss: 1.2416 - val_accuracy: 0.3951\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 9ms/step - loss: 1.3647 - accuracy: 0.3210 - val_loss: 1.3588 - val_accuracy: 0.3704\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.3223 - accuracy: 0.3951 - val_loss: 1.3385 - val_accuracy: 0.3704\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2706 - accuracy: 0.3827 - val_loss: 1.2763 - val_accuracy: 0.4321\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2303 - accuracy: 0.4376 - val_loss: 1.2636 - val_accuracy: 0.3827\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1636 - accuracy: 0.4376 - val_loss: 1.2084 - val_accuracy: 0.4198\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1513 - accuracy: 0.4499 - val_loss: 1.2145 - val_accuracy: 0.4198\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1072 - accuracy: 0.4513 - val_loss: 1.1730 - val_accuracy: 0.4321\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0744 - accuracy: 0.4911 - val_loss: 1.1553 - val_accuracy: 0.4198\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0502 - accuracy: 0.5130 - val_loss: 1.1368 - val_accuracy: 0.4568\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0265 - accuracy: 0.5254 - val_loss: 1.2781 - val_accuracy: 0.4198\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0008 - accuracy: 0.5103 - val_loss: 1.1542 - val_accuracy: 0.3580\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0074 - accuracy: 0.5213 - val_loss: 1.1149 - val_accuracy: 0.3951\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9556 - accuracy: 0.5487 - val_loss: 1.1709 - val_accuracy: 0.3580\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9638 - accuracy: 0.5405 - val_loss: 1.1636 - val_accuracy: 0.3951\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9414 - accuracy: 0.5706 - val_loss: 1.1617 - val_accuracy: 0.3827\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9426 - accuracy: 0.5638 - val_loss: 1.0981 - val_accuracy: 0.4198\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9295 - accuracy: 0.5542 - val_loss: 1.1028 - val_accuracy: 0.3951\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8987 - accuracy: 0.5830 - val_loss: 1.1064 - val_accuracy: 0.4691\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8878 - accuracy: 0.5871 - val_loss: 1.3531 - val_accuracy: 0.3580\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9461 - accuracy: 0.5679 - val_loss: 1.0577 - val_accuracy: 0.4938\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8943 - accuracy: 0.5789 - val_loss: 1.1030 - val_accuracy: 0.4198\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8811 - accuracy: 0.5981 - val_loss: 1.0614 - val_accuracy: 0.4198\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8493 - accuracy: 0.6392 - val_loss: 1.0651 - val_accuracy: 0.4691\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8648 - accuracy: 0.6077 - val_loss: 1.0949 - val_accuracy: 0.4321\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8673 - accuracy: 0.6036 - val_loss: 1.0723 - val_accuracy: 0.4568\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8440 - accuracy: 0.6159 - val_loss: 1.1055 - val_accuracy: 0.4321\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8123 - accuracy: 0.6187 - val_loss: 1.0952 - val_accuracy: 0.4568\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8338 - accuracy: 0.6324 - val_loss: 1.0891 - val_accuracy: 0.3951\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8358 - accuracy: 0.6132 - val_loss: 1.0962 - val_accuracy: 0.4198\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8205 - accuracy: 0.6187 - val_loss: 1.1183 - val_accuracy: 0.4074\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 8ms/step - loss: 1.3908 - accuracy: 0.3471 - val_loss: 1.4264 - val_accuracy: 0.3210\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2881 - accuracy: 0.3951 - val_loss: 1.2778 - val_accuracy: 0.5062\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2119 - accuracy: 0.4623 - val_loss: 1.2237 - val_accuracy: 0.4815\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1899 - accuracy: 0.4417 - val_loss: 1.1941 - val_accuracy: 0.4321\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1459 - accuracy: 0.4746 - val_loss: 1.1636 - val_accuracy: 0.3951\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0704 - accuracy: 0.4897 - val_loss: 1.0775 - val_accuracy: 0.4938\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0387 - accuracy: 0.5199 - val_loss: 1.0452 - val_accuracy: 0.5062\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9962 - accuracy: 0.5254 - val_loss: 0.9018 - val_accuracy: 0.4815\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9600 - accuracy: 0.5418 - val_loss: 0.8184 - val_accuracy: 0.5432\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9219 - accuracy: 0.5775 - val_loss: 0.9135 - val_accuracy: 0.5432\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9006 - accuracy: 0.5789 - val_loss: 0.8794 - val_accuracy: 0.5062\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9009 - accuracy: 0.5816 - val_loss: 0.8167 - val_accuracy: 0.5432\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8605 - accuracy: 0.6214 - val_loss: 0.7847 - val_accuracy: 0.4568\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8489 - accuracy: 0.5885 - val_loss: 0.7530 - val_accuracy: 0.5309\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8228 - accuracy: 0.6269 - val_loss: 0.7607 - val_accuracy: 0.5679\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7979 - accuracy: 0.6118 - val_loss: 0.8419 - val_accuracy: 0.5062\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8433 - accuracy: 0.6022 - val_loss: 0.7000 - val_accuracy: 0.5185\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7769 - accuracy: 0.6283 - val_loss: 0.7853 - val_accuracy: 0.5062\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7381 - accuracy: 0.6433 - val_loss: 0.6540 - val_accuracy: 0.5679\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7566 - accuracy: 0.6392 - val_loss: 0.7755 - val_accuracy: 0.4815\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7365 - accuracy: 0.6557 - val_loss: 0.6691 - val_accuracy: 0.5679\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7244 - accuracy: 0.6488 - val_loss: 0.6923 - val_accuracy: 0.5926\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.7677 - accuracy: 0.6214 - val_loss: 0.7003 - val_accuracy: 0.6173\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9271 - accuracy: 0.5597 - val_loss: 0.8628 - val_accuracy: 0.5185\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9808 - accuracy: 0.5377 - val_loss: 0.8093 - val_accuracy: 0.5185\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8904 - accuracy: 0.5377 - val_loss: 0.8099 - val_accuracy: 0.5432\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8595 - accuracy: 0.5789 - val_loss: 0.7346 - val_accuracy: 0.5309\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8423 - accuracy: 0.5761 - val_loss: 0.7578 - val_accuracy: 0.5556\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8298 - accuracy: 0.5652 - val_loss: 0.7985 - val_accuracy: 0.4938\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8353 - accuracy: 0.5652 - val_loss: 0.7188 - val_accuracy: 0.5432\n",
      "68/68 [==============================] - 0s 2ms/step\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "Fold 2 - CNN Accuracy: 0.4333, CNN F1 Score: 0.4030\n",
      "Fold 2 - LSTM Accuracy: 0.5259, LSTM F1 Score: 0.5310\n",
      "Fold 2 - Hybrid Accuracy: 0.5519, Hybrid F1 Score: 0.5468\n",
      "Training fold 3...\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 2s 4ms/step - loss: 176098720.0000 - accuracy: 0.2881 - val_loss: 472273.1875 - val_accuracy: 0.2222\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 102535768.0000 - accuracy: 0.2675 - val_loss: 168756.4375 - val_accuracy: 0.3210\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 47013536.0000 - accuracy: 0.3416 - val_loss: 47380.1992 - val_accuracy: 0.2963\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 12820955.0000 - accuracy: 0.3265 - val_loss: 35896.0391 - val_accuracy: 0.3457\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 12080465.0000 - accuracy: 0.3512 - val_loss: 68972.8984 - val_accuracy: 0.2963\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3027886.5000 - accuracy: 0.3841 - val_loss: 46594.3906 - val_accuracy: 0.2840\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1926036.5000 - accuracy: 0.3813 - val_loss: 20125.3652 - val_accuracy: 0.2716\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2382202.0000 - accuracy: 0.3841 - val_loss: 7077.1572 - val_accuracy: 0.3704\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2827850.5000 - accuracy: 0.3745 - val_loss: 5083.6655 - val_accuracy: 0.4321\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 874986.5625 - accuracy: 0.3882 - val_loss: 4911.0293 - val_accuracy: 0.4444\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 2488645.0000 - accuracy: 0.3635 - val_loss: 1091.7040 - val_accuracy: 0.2840\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 4ms/step - loss: 3684137.0000 - accuracy: 0.2743 - val_loss: 1694.0704 - val_accuracy: 0.2593\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1861432.7500 - accuracy: 0.3059 - val_loss: 1904.7889 - val_accuracy: 0.3210\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 196847.4531 - accuracy: 0.3374 - val_loss: 2104.5522 - val_accuracy: 0.3086\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3587191.0000 - accuracy: 0.3539 - val_loss: 598.6934 - val_accuracy: 0.2840\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 239133.7031 - accuracy: 0.3553 - val_loss: 476.6260 - val_accuracy: 0.4074\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 128671.5703 - accuracy: 0.3663 - val_loss: 1.3055 - val_accuracy: 0.3086\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 2905807.7500 - accuracy: 0.3621 - val_loss: 1.2984 - val_accuracy: 0.3086\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 51466.5469 - accuracy: 0.3731 - val_loss: 1.3120 - val_accuracy: 0.4074\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 35745.0195 - accuracy: 0.3813 - val_loss: 1.3012 - val_accuracy: 0.3704\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 134915.1250 - accuracy: 0.3868 - val_loss: 1412.6545 - val_accuracy: 0.3580\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 61491.1992 - accuracy: 0.3759 - val_loss: 52.6843 - val_accuracy: 0.3704\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 26935.2871 - accuracy: 0.3731 - val_loss: 1.2722 - val_accuracy: 0.3704\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 294857.9688 - accuracy: 0.4156 - val_loss: 789.6801 - val_accuracy: 0.3580\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 49516.4609 - accuracy: 0.3841 - val_loss: 734.4296 - val_accuracy: 0.3827\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 130170.9531 - accuracy: 0.4252 - val_loss: 707.8749 - val_accuracy: 0.4074\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 165743.5312 - accuracy: 0.4033 - val_loss: 1155.8091 - val_accuracy: 0.3951\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 128988.3984 - accuracy: 0.3964 - val_loss: 1960.8846 - val_accuracy: 0.3704\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 5214142.5000 - accuracy: 0.4184 - val_loss: 3214.7217 - val_accuracy: 0.4074\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 660388.7500 - accuracy: 0.4184 - val_loss: 3257.0386 - val_accuracy: 0.3951\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 9ms/step - loss: 1.3573 - accuracy: 0.3278 - val_loss: 1.2849 - val_accuracy: 0.4321\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2870 - accuracy: 0.4019 - val_loss: 1.2961 - val_accuracy: 0.2840\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2698 - accuracy: 0.4129 - val_loss: 1.2458 - val_accuracy: 0.4198\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2241 - accuracy: 0.4390 - val_loss: 1.2380 - val_accuracy: 0.3827\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1980 - accuracy: 0.4321 - val_loss: 1.2295 - val_accuracy: 0.3827\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1616 - accuracy: 0.4554 - val_loss: 1.2439 - val_accuracy: 0.3951\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1199 - accuracy: 0.4623 - val_loss: 1.2457 - val_accuracy: 0.3951\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1098 - accuracy: 0.4705 - val_loss: 1.1674 - val_accuracy: 0.3580\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0791 - accuracy: 0.4540 - val_loss: 1.2042 - val_accuracy: 0.3704\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0580 - accuracy: 0.4870 - val_loss: 1.1553 - val_accuracy: 0.3827\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0352 - accuracy: 0.4979 - val_loss: 1.1161 - val_accuracy: 0.4074\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0152 - accuracy: 0.5130 - val_loss: 1.1372 - val_accuracy: 0.4321\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9824 - accuracy: 0.5405 - val_loss: 1.1420 - val_accuracy: 0.4815\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9781 - accuracy: 0.5267 - val_loss: 1.1327 - val_accuracy: 0.3827\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9811 - accuracy: 0.5336 - val_loss: 1.1047 - val_accuracy: 0.3951\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9612 - accuracy: 0.5391 - val_loss: 1.0858 - val_accuracy: 0.4444\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9595 - accuracy: 0.5405 - val_loss: 1.1001 - val_accuracy: 0.3457\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9733 - accuracy: 0.5240 - val_loss: 1.1161 - val_accuracy: 0.3951\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9222 - accuracy: 0.5556 - val_loss: 1.0833 - val_accuracy: 0.4074\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9368 - accuracy: 0.5597 - val_loss: 1.0740 - val_accuracy: 0.4198\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9530 - accuracy: 0.5679 - val_loss: 1.0833 - val_accuracy: 0.4074\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9254 - accuracy: 0.5871 - val_loss: 1.0843 - val_accuracy: 0.4444\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8798 - accuracy: 0.5844 - val_loss: 1.0645 - val_accuracy: 0.4691\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9319 - accuracy: 0.5638 - val_loss: 1.1289 - val_accuracy: 0.3580\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9321 - accuracy: 0.5748 - val_loss: 1.1062 - val_accuracy: 0.4321\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8896 - accuracy: 0.6036 - val_loss: 1.0948 - val_accuracy: 0.4321\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8500 - accuracy: 0.6145 - val_loss: 1.0294 - val_accuracy: 0.4321\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8794 - accuracy: 0.5885 - val_loss: 1.0249 - val_accuracy: 0.4691\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8471 - accuracy: 0.5967 - val_loss: 1.0445 - val_accuracy: 0.4568\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8541 - accuracy: 0.6132 - val_loss: 1.0929 - val_accuracy: 0.3704\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 8ms/step - loss: 1.4614 - accuracy: 0.3073 - val_loss: 1.3516 - val_accuracy: 0.2716\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.3015 - accuracy: 0.3772 - val_loss: 1.4789 - val_accuracy: 0.2840\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2585 - accuracy: 0.3868 - val_loss: 1.2905 - val_accuracy: 0.4198\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2376 - accuracy: 0.3841 - val_loss: 1.2841 - val_accuracy: 0.2963\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1721 - accuracy: 0.4239 - val_loss: 1.2119 - val_accuracy: 0.4321\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1430 - accuracy: 0.4691 - val_loss: 1.1522 - val_accuracy: 0.4321\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0878 - accuracy: 0.4801 - val_loss: 1.1045 - val_accuracy: 0.4321\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0457 - accuracy: 0.4952 - val_loss: 1.0290 - val_accuracy: 0.4568\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0117 - accuracy: 0.4938 - val_loss: 1.0371 - val_accuracy: 0.3580\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9833 - accuracy: 0.4979 - val_loss: 1.0410 - val_accuracy: 0.3951\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9586 - accuracy: 0.5364 - val_loss: 0.9621 - val_accuracy: 0.4444\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9884 - accuracy: 0.5007 - val_loss: 0.9840 - val_accuracy: 0.4568\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9679 - accuracy: 0.5130 - val_loss: 1.0204 - val_accuracy: 0.3827\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9513 - accuracy: 0.5350 - val_loss: 0.9574 - val_accuracy: 0.4198\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9427 - accuracy: 0.5295 - val_loss: 1.0261 - val_accuracy: 0.3827\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9100 - accuracy: 0.5487 - val_loss: 0.9134 - val_accuracy: 0.5432\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8886 - accuracy: 0.5446 - val_loss: 1.0306 - val_accuracy: 0.4321\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8730 - accuracy: 0.5652 - val_loss: 0.9165 - val_accuracy: 0.5309\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8920 - accuracy: 0.5624 - val_loss: 0.9559 - val_accuracy: 0.4198\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8455 - accuracy: 0.5761 - val_loss: 0.9294 - val_accuracy: 0.4198\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8411 - accuracy: 0.5761 - val_loss: 0.8354 - val_accuracy: 0.4444\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8294 - accuracy: 0.5789 - val_loss: 0.8497 - val_accuracy: 0.4815\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8172 - accuracy: 0.6036 - val_loss: 0.7932 - val_accuracy: 0.5309\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8437 - accuracy: 0.5652 - val_loss: 1.0338 - val_accuracy: 0.4938\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8389 - accuracy: 0.5597 - val_loss: 0.8609 - val_accuracy: 0.4691\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8725 - accuracy: 0.5597 - val_loss: 0.8049 - val_accuracy: 0.4444\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8303 - accuracy: 0.5734 - val_loss: 0.8513 - val_accuracy: 0.3951\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8297 - accuracy: 0.5885 - val_loss: 0.8464 - val_accuracy: 0.4691\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8312 - accuracy: 0.5775 - val_loss: 0.9905 - val_accuracy: 0.4074\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8160 - accuracy: 0.5816 - val_loss: 0.8849 - val_accuracy: 0.3827\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "68/68 [==============================] - 0s 2ms/step\n",
      "Fold 3 - CNN Accuracy: 0.4481, CNN F1 Score: 0.4311\n",
      "Fold 3 - LSTM Accuracy: 0.5667, LSTM F1 Score: 0.5648\n",
      "Fold 3 - Hybrid Accuracy: 0.6481, Hybrid F1 Score: 0.6480\n",
      "Training fold 4...\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 2s 4ms/step - loss: 156873024.0000 - accuracy: 0.2401 - val_loss: 2128.1890 - val_accuracy: 0.3210\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 85906112.0000 - accuracy: 0.2826 - val_loss: 1001.5795 - val_accuracy: 0.2593\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 39919256.0000 - accuracy: 0.2757 - val_loss: 696.5295 - val_accuracy: 0.2099\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 24399582.0000 - accuracy: 0.3032 - val_loss: 41.1241 - val_accuracy: 0.2716\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 27324022.0000 - accuracy: 0.2840 - val_loss: 1.3545 - val_accuracy: 0.2716\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 13821778.0000 - accuracy: 0.2936 - val_loss: 79.5357 - val_accuracy: 0.2346\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 9882376.0000 - accuracy: 0.3196 - val_loss: 14.1654 - val_accuracy: 0.2222\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 505248.2500 - accuracy: 0.3539 - val_loss: 1.3878 - val_accuracy: 0.2840\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3528832.2500 - accuracy: 0.3594 - val_loss: 1.3514 - val_accuracy: 0.2963\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1888229.5000 - accuracy: 0.3663 - val_loss: 1.3869 - val_accuracy: 0.2346\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 16505280.0000 - accuracy: 0.3306 - val_loss: 1.3777 - val_accuracy: 0.3951\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 9364550.0000 - accuracy: 0.3580 - val_loss: 1.3840 - val_accuracy: 0.2346\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 10419627.0000 - accuracy: 0.3471 - val_loss: 4.5408 - val_accuracy: 0.2346\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1617424.1250 - accuracy: 0.3649 - val_loss: 305.8634 - val_accuracy: 0.2469\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3275669.2500 - accuracy: 0.3608 - val_loss: 1.3806 - val_accuracy: 0.2840\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3247113.2500 - accuracy: 0.3388 - val_loss: 1.3741 - val_accuracy: 0.2593\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 4040954.0000 - accuracy: 0.3580 - val_loss: 1.3701 - val_accuracy: 0.3827\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 5585264.5000 - accuracy: 0.3704 - val_loss: 1.3709 - val_accuracy: 0.3457\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 936631.0625 - accuracy: 0.3649 - val_loss: 1.3759 - val_accuracy: 0.2346\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 396366.5000 - accuracy: 0.3621 - val_loss: 1.3729 - val_accuracy: 0.2346\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 669166.3750 - accuracy: 0.3745 - val_loss: 1.3737 - val_accuracy: 0.2593\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 828511.0625 - accuracy: 0.3621 - val_loss: 1.3782 - val_accuracy: 0.2840\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 15323.4512 - accuracy: 0.3306 - val_loss: 1.3740 - val_accuracy: 0.2840\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 5990.6880 - accuracy: 0.3553 - val_loss: 1.3675 - val_accuracy: 0.1605\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 3894562.5000 - accuracy: 0.3553 - val_loss: 1.3772 - val_accuracy: 0.2222\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1641741.8750 - accuracy: 0.3923 - val_loss: 1.3726 - val_accuracy: 0.2346\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 30409.1914 - accuracy: 0.3567 - val_loss: 1.3660 - val_accuracy: 0.2963\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 1840900.8750 - accuracy: 0.3539 - val_loss: 1.3627 - val_accuracy: 0.2469\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 28459124.0000 - accuracy: 0.3786 - val_loss: 1.3588 - val_accuracy: 0.2716\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 3ms/step - loss: 83120432.0000 - accuracy: 0.3567 - val_loss: 1.3701 - val_accuracy: 0.2346\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 9ms/step - loss: 1.3561 - accuracy: 0.3278 - val_loss: 1.4118 - val_accuracy: 0.3333\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.2962 - accuracy: 0.4005 - val_loss: 1.3594 - val_accuracy: 0.3333\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2503 - accuracy: 0.4362 - val_loss: 1.3628 - val_accuracy: 0.3210\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1923 - accuracy: 0.4746 - val_loss: 1.3061 - val_accuracy: 0.3086\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1514 - accuracy: 0.4691 - val_loss: 1.3161 - val_accuracy: 0.3333\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.1134 - accuracy: 0.4979 - val_loss: 1.2801 - val_accuracy: 0.3580\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0800 - accuracy: 0.4966 - val_loss: 1.2684 - val_accuracy: 0.3951\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0610 - accuracy: 0.5062 - val_loss: 1.2571 - val_accuracy: 0.3704\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0500 - accuracy: 0.5007 - val_loss: 1.2352 - val_accuracy: 0.3580\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9940 - accuracy: 0.5144 - val_loss: 1.2487 - val_accuracy: 0.4321\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0528 - accuracy: 0.5130 - val_loss: 1.2835 - val_accuracy: 0.4198\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 1.0255 - accuracy: 0.5213 - val_loss: 1.2304 - val_accuracy: 0.3951\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9905 - accuracy: 0.5418 - val_loss: 1.2180 - val_accuracy: 0.4321\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9596 - accuracy: 0.5405 - val_loss: 1.2163 - val_accuracy: 0.4568\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9361 - accuracy: 0.5871 - val_loss: 1.2340 - val_accuracy: 0.4074\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9400 - accuracy: 0.5693 - val_loss: 1.2057 - val_accuracy: 0.3457\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9257 - accuracy: 0.5967 - val_loss: 1.2414 - val_accuracy: 0.4074\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9335 - accuracy: 0.5775 - val_loss: 1.2808 - val_accuracy: 0.3210\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.9336 - accuracy: 0.5610 - val_loss: 1.2399 - val_accuracy: 0.3704\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8928 - accuracy: 0.6008 - val_loss: 1.1774 - val_accuracy: 0.4321\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8831 - accuracy: 0.5898 - val_loss: 1.2072 - val_accuracy: 0.4568\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8675 - accuracy: 0.5871 - val_loss: 1.2656 - val_accuracy: 0.4691\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8610 - accuracy: 0.6077 - val_loss: 1.2670 - val_accuracy: 0.4321\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8205 - accuracy: 0.6214 - val_loss: 1.2698 - val_accuracy: 0.4568\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8543 - accuracy: 0.6022 - val_loss: 1.3986 - val_accuracy: 0.4321\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8091 - accuracy: 0.6173 - val_loss: 1.2375 - val_accuracy: 0.4568\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8352 - accuracy: 0.6049 - val_loss: 1.2480 - val_accuracy: 0.4568\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 7ms/step - loss: 0.8106 - accuracy: 0.6529 - val_loss: 1.4290 - val_accuracy: 0.3704\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8065 - accuracy: 0.6392 - val_loss: 1.2516 - val_accuracy: 0.4321\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8278 - accuracy: 0.6392 - val_loss: 1.2741 - val_accuracy: 0.4074\n",
      "Epoch 1/30\n",
      "183/183 [==============================] - 3s 8ms/step - loss: 1.3929 - accuracy: 0.3128 - val_loss: 1.3807 - val_accuracy: 0.2840\n",
      "Epoch 2/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.3745 - accuracy: 0.3457 - val_loss: 1.2917 - val_accuracy: 0.2716\n",
      "Epoch 3/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2522 - accuracy: 0.4184 - val_loss: 1.3521 - val_accuracy: 0.4321\n",
      "Epoch 4/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1817 - accuracy: 0.4486 - val_loss: 1.2943 - val_accuracy: 0.4074\n",
      "Epoch 5/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.2015 - accuracy: 0.4513 - val_loss: 1.2407 - val_accuracy: 0.4074\n",
      "Epoch 6/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.1296 - accuracy: 0.4774 - val_loss: 1.2074 - val_accuracy: 0.3951\n",
      "Epoch 7/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0675 - accuracy: 0.5048 - val_loss: 1.1613 - val_accuracy: 0.3951\n",
      "Epoch 8/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0548 - accuracy: 0.4938 - val_loss: 1.1245 - val_accuracy: 0.3827\n",
      "Epoch 9/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0286 - accuracy: 0.4842 - val_loss: 1.1153 - val_accuracy: 0.3827\n",
      "Epoch 10/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0021 - accuracy: 0.5117 - val_loss: 1.0969 - val_accuracy: 0.4444\n",
      "Epoch 11/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 1.0032 - accuracy: 0.5103 - val_loss: 1.0715 - val_accuracy: 0.3457\n",
      "Epoch 12/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9727 - accuracy: 0.5377 - val_loss: 0.9843 - val_accuracy: 0.3827\n",
      "Epoch 13/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9680 - accuracy: 0.5432 - val_loss: 0.9563 - val_accuracy: 0.4321\n",
      "Epoch 14/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9534 - accuracy: 0.5528 - val_loss: 0.9437 - val_accuracy: 0.5185\n",
      "Epoch 15/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.9215 - accuracy: 0.5322 - val_loss: 0.9075 - val_accuracy: 0.5185\n",
      "Epoch 16/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8962 - accuracy: 0.5802 - val_loss: 0.8576 - val_accuracy: 0.4444\n",
      "Epoch 17/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8848 - accuracy: 0.5583 - val_loss: 0.9667 - val_accuracy: 0.5062\n",
      "Epoch 18/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8466 - accuracy: 0.5940 - val_loss: 0.8921 - val_accuracy: 0.5309\n",
      "Epoch 19/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8823 - accuracy: 0.5514 - val_loss: 0.8445 - val_accuracy: 0.4568\n",
      "Epoch 20/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8643 - accuracy: 0.5720 - val_loss: 0.8200 - val_accuracy: 0.5062\n",
      "Epoch 21/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8587 - accuracy: 0.5624 - val_loss: 0.8931 - val_accuracy: 0.3951\n",
      "Epoch 22/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8548 - accuracy: 0.5789 - val_loss: 0.8511 - val_accuracy: 0.4815\n",
      "Epoch 23/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8183 - accuracy: 0.5953 - val_loss: 0.8119 - val_accuracy: 0.5556\n",
      "Epoch 24/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8476 - accuracy: 0.5679 - val_loss: 0.8440 - val_accuracy: 0.5679\n",
      "Epoch 25/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8293 - accuracy: 0.5624 - val_loss: 0.8333 - val_accuracy: 0.4568\n",
      "Epoch 26/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8367 - accuracy: 0.5912 - val_loss: 0.8000 - val_accuracy: 0.5556\n",
      "Epoch 27/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8046 - accuracy: 0.5898 - val_loss: 0.8072 - val_accuracy: 0.4815\n",
      "Epoch 28/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8146 - accuracy: 0.5542 - val_loss: 0.7896 - val_accuracy: 0.5309\n",
      "Epoch 29/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8080 - accuracy: 0.6132 - val_loss: 0.7929 - val_accuracy: 0.5062\n",
      "Epoch 30/30\n",
      "183/183 [==============================] - 1s 6ms/step - loss: 0.8412 - accuracy: 0.5926 - val_loss: 0.8860 - val_accuracy: 0.4938\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "68/68 [==============================] - 0s 3ms/step\n",
      "68/68 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Flatten, MaxPooling1D, Reshape\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# GPU 메모리 할당 방식 변경\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "# 데이터 로드 및 전처리\n",
    "# X와 y 배열 준비\n",
    "X = _X.transpose(0, 5, 1, 2, 3, 4)\n",
    "X = X.reshape(X.shape[0], X.shape[1], np.prod(X.shape[2:]))\n",
    "y = np.array(y)  # y는 라벨 데이터입니다.\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y_onehot = to_categorical(y)\n",
    "\n",
    "# KFold 설정\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "\n",
    "# 모델 정의 함수들\n",
    "def create_cnn_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(output_shape, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_lstm_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='tanh', input_shape=input_shape),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(output_shape, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_hybrid_model(input_shape, output_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(units=64, activation='tanh', return_sequences=True),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(output_shape, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "# KFold 교차 검증 수행\n",
    "fold_no = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f'Training fold {fold_no}...')\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_onehot[train_index], y_onehot[test_index]\n",
    "\n",
    "    # Conv1D와 LSTM 모델 정의\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], y_train.shape[1]\n",
    "\n",
    "    cnn_model = create_cnn_model((n_timesteps, n_features), n_outputs)\n",
    "    lstm_model = create_lstm_model((n_timesteps, n_features), n_outputs)\n",
    "    hybrid_model = create_hybrid_model((n_timesteps, n_features), n_outputs)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    hybrid_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 훈련\n",
    "    train_epochs = 30\n",
    "    batch_size = 4  # 배치 크기 줄이기\n",
    "    cnn_model.fit(X_train, y_train, epochs=train_epochs, batch_size=batch_size, verbose=True, validation_split=0.1)\n",
    "    lstm_model.fit(X_train, y_train, epochs=train_epochs, batch_size=batch_size, verbose=True, validation_split=0.1)\n",
    "    hybrid_model.fit(X_train, y_train, epochs=train_epochs, batch_size=batch_size, verbose=True, validation_split=0.1)\n",
    "\n",
    "    # 예측 및 평가\n",
    "    predy_cnn = np.argmax(cnn_model.predict(X_test, batch_size=batch_size), axis=-1)\n",
    "    predy_lstm = np.argmax(lstm_model.predict(X_test, batch_size=batch_size), axis=-1)\n",
    "    predy_hybrid = np.argmax(hybrid_model.predict(X_test, batch_size=batch_size), axis=-1)\n",
    "\n",
    "    y_test_labels = np.argmax(y_test, axis=-1)\n",
    "\n",
    "    accuracy_cnn = accuracy_score(y_test_labels, predy_cnn)\n",
    "    f1_cnn = f1_score(y_test_labels, predy_cnn, average='weighted')\n",
    "\n",
    "    accuracy_lstm = accuracy_score(y_test_labels, predy_lstm)\n",
    "    f1_lstm = f1_score(y_test_labels, predy_lstm, average='weighted')\n",
    "\n",
    "    accuracy_hybrid = accuracy_score(y_test_labels, predy_hybrid)\n",
    "    f1_hybrid = f1_score(y_test_labels, predy_hybrid, average='weighted')\n",
    "\n",
    "    print(f'Fold {fold_no} - CNN Accuracy: {accuracy_cnn:.4f}, CNN F1 Score: {f1_cnn:.4f}')\n",
    "    print(f'Fold {fold_no} - LSTM Accuracy: {accuracy_lstm:.4f}, LSTM F1 Score: {f1_lstm:.4f}')\n",
    "    print(f'Fold {fold_no} - Hybrid Accuracy: {accuracy_hybrid:.4f}, Hybrid F1 Score: {f1_hybrid:.4f}')\n",
    "\n",
    "    accuracy_list.append((accuracy_cnn, accuracy_lstm, accuracy_hybrid))\n",
    "    f1_list.append((f1_cnn, f1_lstm, f1_hybrid))\n",
    "\n",
    "    fold_no += 1\n",
    "\n",
    "    # GPU 메모리 초기화\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "# 최종 결과 출력\n",
    "print('4-Fold Cross Validation Results:')\n",
    "accuracy_array = np.array(accuracy_list)\n",
    "f1_array = np.array(f1_list)\n",
    "print(f'CNN Accuracy: {np.mean(accuracy_array[:,0]):.4f} ± {np.std(accuracy_array[:,0]):.4f}')\n",
    "print(f'LSTM Accuracy: {np.mean(accuracy_array[:,1]):.4f} ± {np.std(accuracy_array[:,1]):.4f}')\n",
    "print(f'Hybrid Accuracy: {np.mean(accuracy_array[:,2]):.4f} ± {np.std(accuracy_array[:,2]):.4f}')\n",
    "print(f'CNN F1 Score: {np.mean(f1_array[:,0]):.4f} ± {np.std(f1_array[:,0]):.4f}')\n",
    "print(f'LSTM F1 Score: {np.mean(f1_array[:,1]):.4f} ± {np.std(f1_array[:,1]):.4f}')\n",
    "print(f'Hybrid F1 Score: {np.mean(f1_array[:,2]):.4f} ± {np.std(f1_array[:,2]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b826c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
