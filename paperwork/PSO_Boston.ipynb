{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e88cd0c-8e28-46c3-92d5-b3b32bd94be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4274b39b-e8b0-41c2-8dfa-d8ab8d55dd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  PRICE  \n",
       "0        -122.23  4.526  \n",
       "1        -122.22  3.585  \n",
       "2        -122.24  3.521  \n",
       "3        -122.25  3.413  \n",
       "4        -122.25  3.422  \n",
       "...          ...    ...  \n",
       "20635    -121.09  0.781  \n",
       "20636    -121.21  0.771  \n",
       "20637    -121.22  0.923  \n",
       "20638    -121.32  0.847  \n",
       "20639    -121.24  0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "df = pd.read_csv(\"boston.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486fd61f-675b-4130-b099-07c8cfc27692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_columns = df.dtypes[df.dtypes == object]\n",
    "string_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c68334f-e86e-4674-a2e5-e15e9656745e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "      <td>2.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "      <td>1.153956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "      <td>0.149990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "      <td>1.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "      <td>1.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "      <td>2.647250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "      <td>5.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude         PRICE  \n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704      2.068558  \n",
       "std       10.386050      2.135952      2.003532      1.153956  \n",
       "min        0.692308     32.540000   -124.350000      0.149990  \n",
       "25%        2.429741     33.930000   -121.800000      1.196000  \n",
       "50%        2.818116     34.260000   -118.490000      1.797000  \n",
       "75%        3.282261     37.710000   -118.010000      2.647250  \n",
       "max     1243.333333     41.950000   -114.310000      5.000010  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee1581f1-ef6f-48c5-aba5-42d59020f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "PRICE         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92792935-416d-48f9-a948-1d0deed32b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('PRICE' , axis = 1)\n",
    "y = df['PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9492aa-0b12-4c20-aa79-51df5bf44896",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ac21f8-960a-4555-b080-d78428ec9a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5160, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00cbda43-e38e-4333-9b27-d63c04000ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66969649, 2.50779003, 1.3004879 , ..., 2.50779003, 1.66969649,\n",
       "       1.91710273])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(max_depth=5)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f9926f6-ff9d-4a15-a96e-16aaff0f1d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5160"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c58fca-ea64-4f05-94a2-7e9f42aa31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5338509922374668\n",
      "Mean Absolute Error: 0.5368721761567972\n",
      "R2 Score: 0.6052033386855076\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, prediction))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, prediction))\n",
    "print(\"R2 Score:\", r2_score(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8233ef0-f77b-4519-9cc4-8073f067b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patterens = []\n",
    "accuracies = []\n",
    "def FitnessFunction(ffX, ffY): # 회귀 모델을 사용한 적합도 함수\n",
    "    ffx_train, ffx_test, ffy_train, ffy_test = train_test_split(ffX, ffY, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(ffx_train, ffy_train)\n",
    "    prediction = model.predict(ffx_test)\n",
    "    \n",
    "    mse = mean_squared_error(ffy_test, prediction)\n",
    "    mae = mean_absolute_error(ffy_test, prediction)\n",
    "    r2 = r2_score(ffy_test, prediction)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "def population_initialization(df):\n",
    "    sX = df.drop('PRICE', axis=1)\n",
    "    sY = df['PRICE']\n",
    "    \n",
    "    columns = sX.columns\n",
    "    selected = np.random.randint(2, size=len(columns))\n",
    "    \n",
    "    modified_dataset = pd.DataFrame()\n",
    "    for i in range(len(columns)):\n",
    "        if selected[i] == 1:\n",
    "            modified_dataset[columns[i]] = sX[columns[i]]\n",
    "    \n",
    "    population_initialization_display(selected)\n",
    "    return FitnessFunction(modified_dataset, sY), selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1d84004-6076-4e51-8c30-cd478d5e051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_initialization_display(selected):\n",
    "    print(\"Pattern:\", selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6135e8ad-69fe-414d-8710-5a3e233ece66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation(df):\n",
    "    accuracies = []\n",
    "    patterns = []\n",
    "    for i in range(60):\n",
    "        acc, pattern = population_initialization(df)\n",
    "        accuracies.append(acc)\n",
    "        patterns.append(pattern)\n",
    "    return accuracies, patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0f8f917-6c0d-4dd5-85c8-cc16c8513b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sorting(accuracies, patterns): # Sorting both accuracies and patterns list\n",
    "    combined = list(zip(accuracies, patterns))\n",
    "    combined.sort(key=lambda x: x[0])  # accuracies를 기준으로 정렬\n",
    "    accuracies[:], patterns[:] = zip(*combined)  # 분리하여 다시 리스트로 만듦\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91024ce6-7a7b-4255-b316-3f1c4079c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_patteren = []\n",
    "best_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "526b19d1-0721-4f3c-92b2-4e7752cbc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "terminate_accuracy = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba5984de-9e4f-469e-9322-202e30fd1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def PSO(accuracies, patterns, df):\n",
    "    accuracies, patterns = generation(df)\n",
    "    print(\"Highest Accuracy Patterns And Their Accuracies\\n\\n\")\n",
    "    \n",
    "    terminate_accuracy = None\n",
    "    best_pattern = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for _ in range(200): # Termination Criteria\n",
    "        print(\"\\n\")\n",
    "        print(patterns[59], accuracies[59])\n",
    "        Sorting(accuracies, patterns)\n",
    "        \n",
    "        array = patterns\n",
    "        updated = np.array(patterns)\n",
    "        gbest = np.array(patterns[59])\n",
    "        updated = velocity(array, updated, gbest)\n",
    "        updated_accuracies = []\n",
    "        \n",
    "        maxlist = [max(row) for row in updated]\n",
    "        \n",
    "        for i in range(60):\n",
    "            updated[i] = updated[i] / maxlist[i]\n",
    "            updated[i] = [0 if val < 0.5 else 1 for val in updated[i]]\n",
    "        \n",
    "        sX = df.drop('PRICE', axis=1)\n",
    "        sY = df['PRICE']\n",
    "        columns = df.columns\n",
    "\n",
    "        for i in range(60):\n",
    "            modified_dataset = pd.DataFrame()\n",
    "            for j in range(8):  # 8개의 열에 맞게 수정\n",
    "                if updated[i][j] == 1:\n",
    "                    modified_dataset[columns[j]] = sX[columns[j]]\n",
    "            updated_accuracies.append(FitnessFunction(modified_dataset, sY))\n",
    "\n",
    "        pbest = []\n",
    "        pbest_accuracies = []\n",
    "\n",
    "        for i in range(60):\n",
    "            if accuracies[i] <= updated_accuracies[i]:\n",
    "                pbest.append(updated[i]) \n",
    "                pbest_accuracies.append(updated_accuracies[i])\n",
    "            else:\n",
    "                pbest.append(patterns[i]) \n",
    "                pbest_accuracies.append(accuracies[i])\n",
    "\n",
    "        patterns = pbest\n",
    "        accuracies = pbest_accuracies\n",
    "        \n",
    "        if terminate_accuracy == accuracies[59]:\n",
    "            print(\"Loop Terminated Because Of Continuous Similar Results\")\n",
    "            break\n",
    "        \n",
    "        if accuracies[59] == 80:\n",
    "            break\n",
    "            \n",
    "        terminate_accuracy = accuracies[59]\n",
    "        \n",
    "    Sorting(accuracies, patterns)\n",
    "    best_pattern = patterns[59]\n",
    "    best_accuracy = accuracies[59]\n",
    "    \n",
    "    return best_pattern, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e91a2e-130a-4d0f-8eea-88ed7962186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def FitnessFunction(ffX, ffY):\n",
    "    if ffX.empty or ffY.empty:\n",
    "        return float('inf'), float('inf'), float('-inf')\n",
    "    \n",
    "    ffx_train, ffx_test, ffy_train, ffy_test = train_test_split(ffX, ffY, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(ffx_train, ffy_train)\n",
    "    prediction = model.predict(ffx_test)\n",
    "    \n",
    "    mse = mean_squared_error(ffy_test, prediction)\n",
    "    mae = mean_absolute_error(ffy_test, prediction)\n",
    "    r2 = r2_score(ffy_test, prediction)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "def population_initialization_display(selected):\n",
    "    print(\"Pattern:\", selected)\n",
    "\n",
    "def population_initialization(df):\n",
    "    sX = df.drop('PRICE', axis=1)\n",
    "    sY = df['PRICE']\n",
    "    \n",
    "    columns = sX.columns\n",
    "    selected = np.random.randint(2, size=len(columns))\n",
    "    \n",
    "    modified_dataset = pd.DataFrame()\n",
    "    for i in range(len(columns)):\n",
    "        if selected[i] == 1:\n",
    "            modified_dataset[columns[i]] = sX[columns[i]]\n",
    "    \n",
    "    if modified_dataset.empty:\n",
    "        return float('inf'), selected\n",
    "    \n",
    "    population_initialization_display(selected)\n",
    "    return FitnessFunction(modified_dataset, sY), selected\n",
    "\n",
    "def generation(df):\n",
    "    accuracies = []\n",
    "    patterns = []\n",
    "    for i in range(60):\n",
    "        acc, pattern = population_initialization(df)\n",
    "        accuracies.append(acc)\n",
    "        patterns.append(pattern)\n",
    "    return accuracies, patterns\n",
    "\n",
    "def Sorting(accuracies, patterns):\n",
    "    combined = list(zip(accuracies, patterns))\n",
    "    combined.sort(key=lambda x: x[0])  # accuracies를 기준으로 정렬\n",
    "    accuracies[:], patterns[:] = zip(*combined)  # 분리하여 다시 리스트로 만듦\n",
    "\n",
    "def velocity(array, updated, Gbest):\n",
    "    c1 = 0.3\n",
    "    c2 = 0.7\n",
    "    r1 = np.random.random()\n",
    "    r2 = np.random.random()\n",
    "\n",
    "    vel = c1 * r1 * (updated - array) + c2 * r2 * (Gbest - array)\n",
    "    updated = updated + vel\n",
    "    return updated\n",
    "\n",
    "def PSO(accuracies, patterns, df):\n",
    "    accuracies, patterns = generation(df)\n",
    "    print(\"Highest Accuracy Patterns And Their Accuracies\\n\\n\")\n",
    "    \n",
    "    terminate_accuracy = None\n",
    "    best_pattern = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for _ in range(200): # Termination Criteria\n",
    "        print(\"\\n\")\n",
    "        print(patterns[59], accuracies[59])\n",
    "        Sorting(accuracies, patterns)\n",
    "        \n",
    "        array = np.array(patterns)\n",
    "        updated = np.array(patterns)\n",
    "        gbest = np.array(patterns[59])\n",
    "        updated = velocity(array, updated, gbest)\n",
    "        updated_accuracies = []\n",
    "        \n",
    "        maxlist = [max(row) for row in updated]\n",
    "        \n",
    "        for i in range(60):\n",
    "            updated[i] = updated[i] / maxlist[i]\n",
    "            updated[i] = [0 if val < 0.5 else 1 for val in updated[i]]\n",
    "        \n",
    "        sX = df.drop('PRICE', axis=1)\n",
    "        sY = df['PRICE']\n",
    "        columns = df.columns\n",
    "\n",
    "        for i in range(60):\n",
    "            modified_dataset = pd.DataFrame()\n",
    "            for j in range(8):  # 8개의 열에 맞게 수정\n",
    "                if updated[i][j] == 1:\n",
    "                    modified_dataset[columns[j]] = sX[columns[j]]\n",
    "            updated_accuracies.append(FitnessFunction(modified_dataset, sY))\n",
    "\n",
    "        pbest = []\n",
    "        pbest_accuracies = []\n",
    "\n",
    "        for i in range(60):\n",
    "            if accuracies[i] <= updated_accuracies[i]:\n",
    "                pbest.append(updated[i]) \n",
    "                pbest_accuracies.append(updated_accuracies[i])\n",
    "            else:\n",
    "                pbest.append(patterns[i]) \n",
    "                pbest_accuracies.append(accuracies[i])\n",
    "\n",
    "        patterns = pbest\n",
    "        accuracies = pbest_accuracies\n",
    "        \n",
    "        if terminate_accuracy == accuracies[59]:\n",
    "            print(\"Loop Terminated Because Of Continuous Similar Results\")\n",
    "            break\n",
    "        \n",
    "        if accuracies[59] == 80:\n",
    "            break\n",
    "            \n",
    "        terminate_accuracy = accuracies[59]\n",
    "        \n",
    "    Sorting(accuracies, patterns)\n",
    "    best_pattern = patterns[59]\n",
    "    best_accuracy = accuracies[59]\n",
    "    \n",
    "    return best_pattern, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd9d8f87-c01b-48ac-a5ea-8df887e915f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: [1 1 1 1 0 0 0 1]\n",
      "Pattern: [0 1 1 0 0 0 0 0]\n",
      "Pattern: [1 1 0 1 1 0 1 0]\n",
      "Pattern: [1 1 0 0 0 1 1 0]\n",
      "Pattern: [1 1 1 1 1 0 1 1]\n",
      "Pattern: [1 0 1 0 0 0 0 1]\n",
      "Pattern: [1 0 0 0 0 1 1 0]\n",
      "Pattern: [1 1 0 0 1 1 1 0]\n",
      "Pattern: [0 0 0 0 1 1 1 0]\n",
      "Pattern: [1 0 0 1 0 1 1 1]\n",
      "Pattern: [1 0 0 0 1 1 1 0]\n",
      "Pattern: [0 0 1 0 0 1 1 1]\n",
      "Pattern: [1 0 0 0 1 1 1 0]\n",
      "Pattern: [1 0 1 0 1 0 1 1]\n",
      "Pattern: [1 1 1 0 1 1 1 1]\n",
      "Pattern: [0 0 1 0 0 1 1 0]\n",
      "Pattern: [1 1 1 0 1 1 0 0]\n",
      "Pattern: [0 1 1 0 0 1 0 0]\n",
      "Pattern: [1 1 0 1 0 1 0 1]\n",
      "Pattern: [0 1 1 0 0 0 1 0]\n",
      "Pattern: [1 0 0 1 1 0 0 0]\n",
      "Pattern: [1 1 0 1 0 0 0 1]\n",
      "Pattern: [0 0 0 0 0 0 1 1]\n",
      "Pattern: [0 1 1 0 0 1 1 0]\n",
      "Pattern: [1 1 0 0 0 1 1 1]\n",
      "Pattern: [0 0 1 1 1 1 1 1]\n",
      "Pattern: [1 1 1 0 0 1 0 0]\n",
      "Pattern: [0 0 0 1 0 1 0 0]\n",
      "Pattern: [1 1 1 1 1 1 0 1]\n",
      "Pattern: [0 0 1 1 1 1 0 1]\n",
      "Pattern: [1 1 0 0 1 1 1 0]\n",
      "Pattern: [0 0 0 0 1 1 0 0]\n",
      "Pattern: [0 1 0 0 0 0 0 0]\n",
      "Pattern: [1 0 1 0 1 1 1 1]\n",
      "Pattern: [0 1 0 0 1 0 1 0]\n",
      "Pattern: [1 0 0 0 1 0 1 1]\n",
      "Pattern: [0 0 0 1 1 0 0 0]\n",
      "Pattern: [1 1 0 0 0 0 0 1]\n",
      "Pattern: [0 1 1 0 1 1 1 1]\n",
      "Pattern: [0 1 1 0 0 1 1 0]\n",
      "Pattern: [0 0 1 1 0 0 1 1]\n",
      "Pattern: [0 0 0 1 0 0 0 0]\n",
      "Pattern: [1 1 0 1 0 1 0 1]\n",
      "Pattern: [1 1 0 0 1 0 1 1]\n",
      "Pattern: [0 0 1 0 1 1 0 0]\n",
      "Pattern: [0 0 1 0 0 1 1 0]\n",
      "Pattern: [1 1 1 0 0 1 0 0]\n",
      "Pattern: [1 1 0 0 0 0 0 0]\n",
      "Pattern: [1 0 1 1 0 1 1 1]\n",
      "Pattern: [1 0 1 1 1 0 0 0]\n",
      "Pattern: [0 1 1 1 0 0 1 1]\n",
      "Pattern: [0 0 0 1 0 1 1 0]\n",
      "Pattern: [1 1 1 0 1 0 1 0]\n",
      "Pattern: [0 0 1 0 0 1 0 1]\n",
      "Pattern: [1 0 1 1 0 1 0 0]\n",
      "Pattern: [0 1 0 1 1 0 0 0]\n",
      "Pattern: [0 0 0 1 1 0 1 0]\n",
      "Pattern: [1 0 1 0 0 0 1 1]\n",
      "Pattern: [1 0 0 0 0 1 1 0]\n",
      "Pattern: [0 1 0 0 0 0 1 0]\n",
      "Highest Accuracy Patterns And Their Accuracies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 1 0 0 0 0 1 0] (1.0971631473754484, 0.7613678787748477, 0.16273227244803645)\n",
      "\n",
      "\n",
      "[0. 0. 0. 1. 0. 0. 0. 0.] (1.798728508490087, 1.05037037381319, -0.3726466609719892)\n",
      "Loop Terminated Because Of Continuous Similar Results\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "patterns = []\n",
    "best_pattern, best_accuracy = PSO(accuracies, patterns, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "213196fe-c529-4ddb-880d-9eee00090899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Pattern: [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Best Accuracy: (1.802668477371312, 1.051353832094687, -0.37565333213087726)\n",
      "Column Names Which Gave Best Accuracy Are:\n",
      "\n",
      "\n",
      "AveBedrms\n",
      "\n",
      "Best Accuracy Is: (1.802668477371312, 1.051353832094687, -0.37565333213087726)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Pattern:\", best_pattern)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "columns = df.columns[:-1]  # 'PRICE' 열을 제외한 열 이름들\n",
    "print(\"Column Names Which Gave Best Accuracy Are:\")\n",
    "print(\"\\n\")\n",
    "for i in range(len(best_pattern)):\n",
    "    if best_pattern[i] == 1:\n",
    "        print(columns[i])\n",
    "print(\"\\nBest Accuracy Is:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8affcef-b234-413f-865c-32f56da996e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def FitnessFunction(ffX, ffY):\n",
    "    if ffX.empty or ffY.empty:\n",
    "        return float('inf'), float('inf'), float('-inf')\n",
    "    \n",
    "    ffx_train, ffx_test, ffy_train, ffy_test = train_test_split(ffX, ffY, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100)\n",
    "    model.fit(ffx_train, ffy_train)\n",
    "    prediction = model.predict(ffx_test)\n",
    "    \n",
    "    mse = mean_squared_error(ffy_test, prediction)\n",
    "    mae = mean_absolute_error(ffy_test, prediction)\n",
    "    r2 = r2_score(ffy_test, prediction)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "def population_initialization_display(selected):\n",
    "    print(\"Pattern:\", selected)\n",
    "\n",
    "def population_initialization(df):\n",
    "    sX = df.drop('PRICE', axis=1)\n",
    "    sY = df['PRICE']\n",
    "    \n",
    "    columns = sX.columns\n",
    "    selected = np.random.randint(2, size=len(columns))\n",
    "    \n",
    "    modified_dataset = pd.DataFrame()\n",
    "    for i in range(len(columns)):\n",
    "        if selected[i] == 1:\n",
    "            modified_dataset[columns[i]] = sX[columns[i]]\n",
    "    \n",
    "    if modified_dataset.empty:\n",
    "        return float('inf'), selected\n",
    "    \n",
    "    population_initialization_display(selected)\n",
    "    return FitnessFunction(modified_dataset, sY), selected\n",
    "\n",
    "def generation(df, population_size):\n",
    "    accuracies = []\n",
    "    patterns = []\n",
    "    for i in range(population_size):\n",
    "        acc, pattern = population_initialization(df)\n",
    "        accuracies.append(acc)\n",
    "        patterns.append(pattern)\n",
    "    return accuracies, patterns\n",
    "\n",
    "def Sorting(accuracies, patterns):\n",
    "    combined = list(zip(accuracies, patterns))\n",
    "    combined.sort(key=lambda x: x[0])  # accuracies를 기준으로 정렬\n",
    "    accuracies[:], patterns[:] = zip(*combined)  # 분리하여 다시 리스트로 만듦\n",
    "\n",
    "def velocity(array, updated, Gbest):\n",
    "    c1 = 0.3\n",
    "    c2 = 0.7\n",
    "    r1 = np.random.random()\n",
    "    r2 = np.random.random()\n",
    "\n",
    "    vel = c1 * r1 * (updated - array) + c2 * r2 * (Gbest - array)\n",
    "    updated = updated + vel\n",
    "    return updated\n",
    "\n",
    "def PSO(accuracies, patterns, df, population_size=60):\n",
    "    accuracies, patterns = generation(df, population_size)\n",
    "    print(\"Highest Accuracy Patterns And Their Accuracies\\n\\n\")\n",
    "    \n",
    "    terminate_accuracy = None\n",
    "    best_pattern = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for _ in range(200): # Termination Criteria\n",
    "        print(\"\\n\")\n",
    "        for i in range(population_size):\n",
    "            print(patterns[i], accuracies[i])\n",
    "        \n",
    "        Sorting(accuracies, patterns)\n",
    "        \n",
    "        array = np.array(patterns)\n",
    "        updated = np.array(patterns)\n",
    "        gbest = np.array(patterns[-1])  # 마지막 개체 사용\n",
    "        updated = velocity(array, updated, gbest)\n",
    "        updated_accuracies = []\n",
    "        \n",
    "        maxlist = [max(row) for row in updated]\n",
    "        \n",
    "        for i in range(population_size):\n",
    "            updated[i] = updated[i] / maxlist[i]\n",
    "            updated[i] = [0 if val < 0.5 else 1 for val in updated[i]]\n",
    "        \n",
    "        sX = df.drop('PRICE', axis=1)\n",
    "        sY = df['PRICE']\n",
    "        columns = df.columns\n",
    "\n",
    "        for i in range(population_size):\n",
    "            modified_dataset = pd.DataFrame()\n",
    "            for j in range(8):  # 8개의 열에 맞게 수정\n",
    "                if updated[i][j] == 1:\n",
    "                    modified_dataset[columns[j]] = sX[columns[j]]\n",
    "            updated_accuracies.append(FitnessFunction(modified_dataset, sY))\n",
    "\n",
    "        pbest = []\n",
    "        pbest_accuracies = []\n",
    "\n",
    "        for i in range(population_size):\n",
    "            if accuracies[i] <= updated_accuracies[i]:\n",
    "                pbest.append(updated[i]) \n",
    "                pbest_accuracies.append(updated_accuracies[i])\n",
    "            else:\n",
    "                pbest.append(patterns[i]) \n",
    "                pbest_accuracies.append(accuracies[i])\n",
    "\n",
    "        patterns = pbest\n",
    "        accuracies = pbest_accuracies\n",
    "        \n",
    "        if terminate_accuracy == accuracies[-1]:\n",
    "            print(\"Loop Terminated Because Of Continuous Similar Results\")\n",
    "            break\n",
    "        \n",
    "        if accuracies[-1] == 80:\n",
    "            break\n",
    "            \n",
    "        terminate_accuracy = accuracies[-1]\n",
    "        \n",
    "    Sorting(accuracies, patterns)\n",
    "    best_pattern = patterns[-1]\n",
    "    best_accuracy = accuracies[-1]\n",
    "    \n",
    "    return best_pattern, best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aaa9efaf-fb49-4d54-acdd-af88fced1921",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: [0 1 1 1 1 0 0 1]\n",
      "Pattern: [1 0 1 0 0 1 0 0]\n",
      "Pattern: [1 0 1 0 1 0 0 1]\n",
      "Pattern: [1 0 0 1 0 1 1 0]\n",
      "Pattern: [1 0 0 0 0 1 1 1]\n",
      "Pattern: [1 0 0 0 1 1 1 0]\n",
      "Pattern: [0 0 0 1 1 0 0 1]\n",
      "Pattern: [0 0 1 0 1 0 0 1]\n",
      "Pattern: [1 1 1 1 0 0 0 1]\n",
      "Pattern: [1 1 1 0 0 1 0 1]\n",
      "Pattern: [0 1 0 1 0 0 0 1]\n",
      "Pattern: [1 1 0 0 1 0 1 1]\n",
      "Pattern: [1 1 1 0 0 1 0 1]\n",
      "Pattern: [0 0 0 1 1 1 0 1]\n",
      "Pattern: [1 1 0 0 0 0 0 1]\n",
      "Pattern: [1 1 0 1 0 1 1 1]\n",
      "Pattern: [1 1 0 1 0 1 0 1]\n",
      "Pattern: [0 1 0 0 1 1 1 1]\n",
      "Pattern: [0 1 0 1 1 0 0 0]\n",
      "Pattern: [0 0 1 1 1 1 0 1]\n",
      "Pattern: [0 1 1 1 1 0 1 0]\n",
      "Pattern: [1 0 1 1 0 1 1 1]\n",
      "Pattern: [1 0 0 1 1 1 1 1]\n",
      "Pattern: [1 0 1 0 0 0 0 1]\n",
      "Pattern: [0 1 1 1 1 1 0 1]\n",
      "Pattern: [0 0 1 1 0 1 1 0]\n",
      "Pattern: [1 1 0 0 1 1 0 1]\n",
      "Pattern: [1 0 0 0 0 1 1 1]\n",
      "Pattern: [1 1 1 1 1 0 0 0]\n",
      "Pattern: [1 0 0 1 1 1 1 1]\n",
      "Pattern: [0 1 1 1 0 0 0 1]\n",
      "Pattern: [0 0 1 1 0 0 0 1]\n",
      "Pattern: [0 1 0 1 0 1 1 0]\n",
      "Pattern: [1 1 1 1 1 1 1 0]\n",
      "Pattern: [0 0 1 1 0 0 0 0]\n",
      "Pattern: [1 1 1 1 1 1 1 0]\n",
      "Pattern: [0 0 0 0 0 0 0 1]\n",
      "Pattern: [0 0 0 0 1 0 1 1]\n",
      "Pattern: [1 1 0 1 1 0 1 0]\n",
      "Pattern: [0 0 1 1 0 1 1 0]\n",
      "Pattern: [1 0 1 1 0 0 0 0]\n",
      "Pattern: [1 1 1 0 0 0 0 0]\n",
      "Pattern: [0 1 1 1 0 1 0 0]\n",
      "Pattern: [1 0 1 0 0 0 0 0]\n",
      "Pattern: [0 1 0 0 0 1 0 0]\n",
      "Pattern: [0 0 1 0 0 1 0 0]\n",
      "Pattern: [1 1 1 0 1 1 0 0]\n",
      "Pattern: [0 1 0 1 0 0 1 1]\n",
      "Pattern: [0 1 0 1 1 1 1 0]\n",
      "Pattern: [1 1 0 0 0 0 1 1]\n",
      "Pattern: [0 1 0 0 1 1 0 0]\n",
      "Pattern: [0 0 0 0 1 1 0 0]\n",
      "Pattern: [1 0 0 0 0 1 0 1]\n",
      "Pattern: [1 0 1 1 1 1 1 1]\n",
      "Pattern: [0 0 1 1 0 0 1 1]\n",
      "Pattern: [1 0 1 0 1 0 0 0]\n",
      "Pattern: [0 1 0 1 0 0 0 1]\n",
      "Pattern: [0 1 0 1 1 0 0 1]\n",
      "Pattern: [0 0 1 1 0 0 1 1]\n",
      "Pattern: [1 1 0 1 1 0 1 0]\n",
      "Highest Accuracy Patterns And Their Accuracies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 1 1 1 1 0 0 1] (0.5998135940265202, 0.5420140372819768, 0.5422699294752137)\n",
      "[1 0 1 0 0 1 0 0] (0.5411988520325315, 0.5280768839874032, 0.5870000427202202)\n",
      "[1 0 1 0 1 0 0 1] (0.4730125968212135, 0.4738641725290699, 0.639034374248421)\n",
      "[1 0 0 1 0 1 1 0] (0.4206930306975584, 0.449152122892442, 0.678960509517953)\n",
      "[1 0 0 0 0 1 1 1] (0.25613702913426784, 0.3228450574612404, 0.8045365734000788)\n",
      "[1 0 0 0 1 1 1 0] (0.42340592579334607, 0.44639904556686055, 0.6768902435621827)\n",
      "[0 0 0 1 1 0 0 1] (0.936694443603544, 0.7157116486595606, 0.2851892354545923)\n",
      "[0 0 1 0 1 0 0 1] (0.7031724005085255, 0.5917394854166667, 0.4633947018186124)\n",
      "[1 1 1 1 0 0 0 1] (0.43488861865772166, 0.4560093204215117, 0.6681275648450467)\n",
      "[1 1 1 0 0 1 0 1] (0.3595395903987967, 0.40682271383236446, 0.7256279555704475)\n",
      "[0 1 0 1 0 0 0 1] (0.9011670710025018, 0.6896285433341408, 0.3123009030262952)\n",
      "[1 1 0 0 1 0 1 1] (0.24432146765689897, 0.31878886649709315, 0.8135532709911089)\n",
      "[1 1 1 0 0 1 0 1] (0.36021354519362475, 0.4080568577519381, 0.7251136468271322)\n",
      "[0 0 0 1 1 1 0 1] (0.7838260100751255, 0.6374198064680232, 0.4018462761699496)\n",
      "[1 1 0 0 0 0 0 1] (0.4974221556878582, 0.4821113164914406, 0.6204069386371265)\n",
      "[1 1 0 1 0 1 1 1] (0.25920628642924, 0.32631037587209316, 0.8021943601323611)\n",
      "[1 1 0 1 0 1 0 1] (0.36635314326293955, 0.41344486303294586, 0.7204283934663405)\n",
      "[0 1 0 0 1 1 1 1] (0.29299136023985234, 0.358271800266473, 0.7764122765450175)\n",
      "[0 1 0 1 1 0 0 0] (1.4280892217078174, 0.9352178393225128, -0.0898042103045511)\n",
      "[0 0 1 1 1 1 0 1] (0.4792507887340837, 0.48029225687984506, 0.6342738819010285)\n",
      "[0 1 1 1 1 0 1 0] (0.6633130059924927, 0.5770579328246125, 0.49381222426991633)\n",
      "[1 0 1 1 0 1 1 1] (0.25160251971886144, 0.3259208988614342, 0.8079969506492438)\n",
      "[1 0 0 1 1 1 1 1] (0.2588412688702085, 0.32716835709786835, 0.8024729125271421)\n",
      "[1 0 1 0 0 0 0 1] (0.4868133499546413, 0.48020187337693804, 0.6285027361395659)\n",
      "[0 1 1 1 1 1 0 1] (0.4491702494169666, 0.46530847114825585, 0.657228959145308)\n",
      "[0 0 1 1 0 1 1 0] (0.5315557781681978, 0.5157152075823644, 0.5943588704026119)\n",
      "[1 1 0 0 1 1 0 1] (0.3638318741401197, 0.41186907434593034, 0.7223524257071792)\n",
      "[1 0 0 0 0 1 1 1] (0.25378509692267487, 0.3202131744912791, 0.806331381166697)\n",
      "[1 1 1 1 1 0 0 0] (0.5272035948836891, 0.5232429265746125, 0.5976801108372974)\n",
      "[1 0 0 1 1 1 1 1] (0.2596825065579052, 0.327917380765504, 0.8018309467731941)\n",
      "[0 1 1 1 0 0 0 1] (0.606650554495002, 0.543938132630814, 0.5370525045475703)\n",
      "[0 0 1 1 0 0 0 1] (0.6725354987341713, 0.5777288268653101, 0.48677435067868147)\n",
      "[0 1 0 1 0 1 1 0] (0.7389444113632053, 0.6128223508236434, 0.4360963457720135)\n",
      "[1 1 1 1 1 1 1 0] (0.3509253451899059, 0.4098503615310079, 0.7322016629793012)\n",
      "[0 0 1 1 0 0 0 0] (1.1844301679616784, 0.839748096997316, 0.09613701704664446)\n",
      "[1 1 1 1 1 1 1 0] (0.3501710338265582, 0.40814410380329474, 0.7327772934701426)\n",
      "[0 0 0 0 0 0 0 1] (0.9259526687729058, 0.7171159815792152, 0.2933865044057391)\n",
      "[0 0 0 0 1 0 1 1] (0.2785670862732531, 0.3421894311692507, 0.7874197362054073)\n",
      "[1 1 0 1 1 0 1 0] (0.4758526442688162, 0.4821941077761629, 0.6368670757219601)\n",
      "[0 0 1 1 0 1 1 0] (0.5307858248091577, 0.5169711567344962, 0.5949464376215678)\n",
      "[1 0 1 1 0 0 0 0] (0.6467270563680704, 0.5861556476744186, 0.5064693030139031)\n",
      "[1 1 1 0 0 0 0 0] (0.600233600319873, 0.5597451567829458, 0.5419494140481013)\n",
      "[0 1 1 1 0 1 0 0] (0.8108625387038724, 0.6944377820494186, 0.38121414598946135)\n",
      "[1 0 1 0 0 0 0 0] (0.7171522217616163, 0.6230709939437986, 0.45272641315055284)\n",
      "[0 1 0 0 0 1 0 0] (1.4403733121378561, 0.9215809565772078, -0.09917845196041108)\n",
      "[0 0 1 0 0 1 0 0] (1.0827676845395249, 0.8041873242732559, 0.17371774574298293)\n",
      "[1 1 1 0 1 1 0 0] (0.44219121467711986, 0.4716796704215117, 0.6625548038668663)\n",
      "[0 1 0 1 0 0 1 1] (0.2668083168303917, 0.3375246044331396, 0.7963930946287039)\n",
      "[0 1 0 1 1 1 1 0] (0.730195221515591, 0.6120809193798449, 0.4427730322057094)\n",
      "[1 1 0 0 0 0 1 1] (0.24458072230205075, 0.31414251068313964, 0.813355428447707)\n",
      "[0 1 0 0 1 1 0 0] (1.2596543357489878, 0.8662460639131137, 0.03873190991109143)\n",
      "[0 0 0 0 1 1 0 0] (1.42483853284255, 0.9239676457710602, -0.08732354287991928)\n",
      "[1 0 0 0 0 1 0 1] (0.4029968809011991, 0.4329778136143412, 0.6924648048106443)\n",
      "[1 0 1 1 1 1 1 1] (0.2542109076150804, 0.32643220738856604, 0.8060064362834765)\n",
      "[0 0 1 1 0 0 1 1] (0.21278662905402082, 0.29796622885174434, 0.8376181538837846)\n",
      "[1 0 1 0 1 0 0 0] (0.6494775024432741, 0.590951150750969, 0.5043703811346467)\n",
      "[0 1 0 1 0 0 0 1] (0.8967437317076284, 0.6882363217054261, 0.31567644407364925)\n",
      "[0 1 0 1 1 0 0 1] (0.8405487173464592, 0.670529590261628, 0.3585600134739487)\n",
      "[0 0 1 1 0 0 1 1] (0.21357862294243027, 0.29762689898255834, 0.8370137670842737)\n",
      "[1 1 0 1 1 0 1 0] (0.47786849025018463, 0.485026621632752, 0.6353287422590175)\n",
      "\n",
      "\n",
      "[0. 0. 1. 1. 0. 0. 1. 1.] (0.2140161002420147, 0.2993395323643412, 0.836679919173546)\n",
      "[0 0 1 1 0 0 1 1] (0.21357862294243027, 0.29762689898255834, 0.8370137670842737)\n",
      "[1 1 0 0 1 0 1 1] (0.24432146765689897, 0.31878886649709315, 0.8135532709911089)\n",
      "[1. 1. 0. 0. 0. 0. 1. 1.] (0.2449557061990095, 0.31356019018895365, 0.8130692705357991)\n",
      "[1 0 1 1 0 1 1 1] (0.25160251971886144, 0.3259208988614342, 0.8079969506492438)\n",
      "[1 0 0 0 0 1 1 1] (0.25378509692267487, 0.3202131744912791, 0.806331381166697)\n",
      "[1. 0. 1. 1. 1. 1. 1. 1.] (0.2554040206096392, 0.3272615123788761, 0.8050959472572486)\n",
      "[1 0 0 0 0 1 1 1] (0.25613702913426784, 0.3228450574612404, 0.8045365734000788)\n",
      "[1. 0. 0. 1. 1. 1. 1. 1.] (0.2625932365170026, 0.32943219057655054, 0.7996097089707754)\n",
      "[1 1 0 1 0 1 1 1] (0.25920628642924, 0.32631037587209316, 0.8021943601323611)\n",
      "[1. 0. 0. 1. 1. 1. 1. 1.] (0.2604464640174217, 0.3284968074854653, 0.8012479551482877)\n",
      "[0. 1. 0. 1. 0. 0. 1. 1.] (0.26730466492478505, 0.33793278609496136, 0.7960143212055703)\n",
      "[0. 0. 0. 0. 1. 0. 1. 1.] (0.28170510231584156, 0.34403161255652465, 0.7850250517254513)\n",
      "[0. 1. 0. 0. 1. 1. 1. 1.] (0.2944903499774278, 0.359256451768411, 0.7752683666951418)\n",
      "[1. 1. 1. 1. 1. 1. 1. 0.] (0.35115578647955925, 0.4090655678052327, 0.7320258084991507)\n",
      "[1. 1. 1. 1. 1. 1. 1. 0.] (0.35100451326395293, 0.40745798020833346, 0.7321412481963124)\n",
      "[1. 1. 1. 0. 0. 1. 0. 1.] (0.3610184586322386, 0.4082845337209303, 0.7244994008535627)\n",
      "[1. 1. 1. 0. 0. 1. 0. 1.] (0.36415831603032917, 0.40970826114341097, 0.7221033111974116)\n",
      "[1. 1. 0. 0. 1. 1. 0. 1.] (0.3639292425124298, 0.41177875404554276, 0.7222781219028502)\n",
      "[1. 1. 0. 1. 0. 1. 0. 1.] (0.36885683646339085, 0.4138314222383722, 0.7185177737727756)\n",
      "[1. 0. 0. 0. 0. 1. 0. 1.] (0.4083151434902268, 0.43604608301841097, 0.6884063294206428)\n",
      "[1 0 0 1 0 1 1 0] (0.4206930306975584, 0.449152122892442, 0.678960509517953)\n",
      "[1 0 0 0 1 1 1 0] (0.42340592579334607, 0.44639904556686055, 0.6768902435621827)\n",
      "[1 1 1 1 0 0 0 1] (0.43488861865772166, 0.4560093204215117, 0.6681275648450467)\n",
      "[1. 1. 1. 0. 1. 1. 0. 0.] (0.4440638271463798, 0.473331601017442, 0.6611257748382542)\n",
      "[0 1 1 1 1 1 0 1] (0.4491702494169666, 0.46530847114825585, 0.657228959145308)\n",
      "[1. 0. 1. 0. 1. 0. 0. 1.] (0.4732240756928881, 0.4737777161579458, 0.6388729903788153)\n",
      "[1. 1. 0. 1. 1. 0. 1. 0.] (0.4766329459759273, 0.48206733834786836, 0.636271611466092)\n",
      "[1. 1. 0. 1. 1. 0. 1. 0.] (0.48006284354066253, 0.48431550365794585, 0.6336541862029199)\n",
      "[0. 0. 1. 1. 1. 1. 0. 1.] (0.4795030822353398, 0.48003921480135664, 0.6340813515494779)\n",
      "[1 0 1 0 0 0 0 1] (0.4868133499546413, 0.48020187337693804, 0.6285027361395659)\n",
      "[1 1 0 0 0 0 0 1] (0.4974221556878582, 0.4821113164914406, 0.6204069386371265)\n",
      "[1. 1. 1. 1. 1. 0. 0. 0.] (0.5283651756187915, 0.522754828875969, 0.5967936847257627)\n",
      "[0 0 1 1 0 1 1 0] (0.5307858248091577, 0.5169711567344962, 0.5949464376215678)\n",
      "[0. 0. 1. 1. 0. 1. 1. 0.] (0.5347153415488402, 0.5179326554990311, 0.5919477427065212)\n",
      "[1 0 1 0 0 1 0 0] (0.5411988520325315, 0.5280768839874032, 0.5870000427202202)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (0.6016060639208728, 0.543795622625969, 0.5409020588912081)\n",
      "[1. 1. 1. 0. 0. 0. 0. 0.] (0.6010151161690308, 0.5594813927567831, 0.5413530232555054)\n",
      "[0 1 1 1 0 0 0 1] (0.606650554495002, 0.543938132630814, 0.5370525045475703)\n",
      "[1 0 1 1 0 0 0 0] (0.6467270563680704, 0.5861556476744186, 0.5064693030139031)\n",
      "[1. 0. 1. 0. 1. 0. 0. 0.] (0.6561289960075913, 0.5941895016957365, 0.4992944898100572)\n",
      "[0 1 1 1 1 0 1 0] (0.6633130059924927, 0.5770579328246125, 0.49381222426991633)\n",
      "[0. 0. 1. 1. 0. 0. 0. 1.] (0.6779614296292679, 0.5804115442102713, 0.48263371139339484)\n",
      "[0. 0. 1. 0. 1. 0. 0. 1.] (0.7041526317537034, 0.5913343912306203, 0.4626466672267754)\n",
      "[1 0 1 0 0 0 0 0] (0.7171522217616163, 0.6230709939437986, 0.45272641315055284)\n",
      "[0 1 0 1 1 1 1 0] (0.730195221515591, 0.6120809193798449, 0.4427730322057094)\n",
      "[0. 1. 0. 1. 0. 1. 1. 0.] (0.7427585487977899, 0.6146606900678293, 0.4331856991739532)\n",
      "[0 0 0 1 1 1 0 1] (0.7838260100751255, 0.6374198064680232, 0.4018462761699496)\n",
      "[0. 1. 1. 1. 0. 1. 0. 0.] (0.8137119915907381, 0.6947723905523255, 0.37903966997916205)\n",
      "[0 1 0 1 1 0 0 1] (0.8405487173464592, 0.670529590261628, 0.3585600134739487)\n",
      "[0. 1. 0. 1. 0. 0. 0. 1.] (0.9038218263630127, 0.6920613741682816, 0.31027500469639013)\n",
      "[0 1 0 1 0 0 0 1] (0.9011670710025018, 0.6896285433341408, 0.3123009030262952)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.] (0.9267209955763123, 0.7178693022449502, 0.2928001784447877)\n",
      "[0 0 0 1 1 0 0 1] (0.936694443603544, 0.7157116486595606, 0.2851892354545923)\n",
      "[0 0 1 0 0 1 0 0] (1.0827676845395249, 0.8041873242732559, 0.17371774574298293)\n",
      "[0 0 1 1 0 0 0 0] (1.1844301679616784, 0.839748096997316, 0.09613701704664446)\n",
      "[0 1 0 0 1 1 0 0] (1.2596543357489878, 0.8662460639131137, 0.03873190991109143)\n",
      "[0. 0. 0. 0. 1. 1. 0. 0.] (1.425417108749775, 0.9232404951635751, -0.08776506603553869)\n",
      "[0 1 0 1 1 0 0 0] (1.4280892217078174, 0.9352178393225128, -0.0898042103045511)\n",
      "[0 1 0 0 0 1 0 0] (1.4403733121378561, 0.9215809565772078, -0.09917845196041108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[0. 1. 1. 1. 0. 1. 1. 1.] (0.2242639189727193, 0.30352633921996136, 0.828859598265442)\n",
      "[0. 1. 1. 1. 0. 1. 1. 1.] (0.22541114410834964, 0.3034424527131785, 0.8279841272066506)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.43421314982419, 0.9192225783911266, -0.0944775056024767)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4362089541466232, 0.9193890705930365, -0.09600054486393872)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.436663435901102, 0.9187590275128429, -0.09634736922337561)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4358022004427506, 0.9183843753867892, -0.09569014275999499)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4384676364498867, 0.9205911212528454, -0.0977241917106626)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4469847736010455, 0.9228556494569604, -0.10422379396658754)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.442673372085459, 0.9213147298551125, -0.10093367493720318)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4406770372782924, 0.9204373891159099, -0.09941023085194778)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4461402435093662, 0.9229841172542335, -0.1035793157115521)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.435724784660716, 0.9193068226480596, -0.09563106518702358)\n",
      "[0. 1. 0. 0. 1. 1. 1. 1.] (0.2903926234068946, 0.3582486768653102, 0.7783954259862297)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4489651398053627, 0.9226571629784687, -0.10573505208309975)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4383310374600362, 0.9201848895013919, -0.09761995021650405)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.432345020335376, 0.9188603136288374, -0.09305189762829924)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4340080788687317, 0.9189681328230549, -0.0943210117453197)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4440078186512835, 0.9204225729418718, -0.1019520185138898)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.43745134077778, 0.918613406627455, -0.0969486356140683)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4333911683642695, 0.9189864483878101, -0.09385023467136322)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4418121227120375, 0.9202075620706536, -0.10027643785494678)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4361480111400766, 0.9204207073395393, -0.09595403800420366)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4399015071634687, 0.9201021180194585, -0.09881840789613672)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4419398910218981, 0.9213501739031736, -0.10037394047587056)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4311202140319843, 0.9168752588978, -0.09211722278729195)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4407779793301174, 0.9196341290096379, -0.0994872618044984)\n",
      "[1. 0. 1. 0. 1. 0. 0. 1.] (0.4732240756928881, 0.4737777161579458, 0.6388729903788153)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428752303352304, 0.9207403682090369, -0.10108771711267894)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4364577760264217, 0.9202707306885612, -0.09619042594986693)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.442819356771872, 0.9205805714077206, -0.10104507884913971)\n",
      "[1 0 1 0 0 0 0 1] (0.4868133499546413, 0.48020187337693804, 0.6285027361395659)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4425990353386235, 0.9205827717456279, -0.10087694703921857)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4329091439024866, 0.9176910698570638, -0.0934823919064045)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428016174046128, 0.9209485862732442, -0.10103154157371375)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.433706185844366, 0.9188884945420068, -0.09409063097917802)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4385136030969217, 0.9178239898757804, -0.09775926980292082)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4373188556413903, 0.9188225098647448, -0.09684753348596198)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4362898690646033, 0.9190288269832233, -0.0960622926994037)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.440553624013677, 0.9191320542339769, -0.09931605165547963)\n",
      "[1 0 1 1 0 0 0 0] (0.6467270563680704, 0.5861556476744186, 0.5064693030139031)\n",
      "[1. 0. 1. 0. 1. 0. 0. 0.] (0.6561289960075913, 0.5941895016957365, 0.4992944898100572)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4331546309885776, 0.9174075787387527, -0.09366972814277608)\n",
      "[0. 0. 1. 1. 0. 0. 0. 1.] (0.6779614296292679, 0.5804115442102713, 0.48263371139339484)\n",
      "[0. 0. 1. 0. 1. 0. 0. 1.] (0.7041526317537034, 0.5913343912306203, 0.4626466672267754)\n",
      "[1 0 1 0 0 0 0 0] (0.7171522217616163, 0.6230709939437986, 0.45272641315055284)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428251804607315, 0.9222238270821796, -0.10104952302569559)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4337238387001967, 0.9206212519869408, -0.09410410223595655)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4418880717819713, 0.9206662392485118, -0.10033439614979578)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4400392586072304, 0.9200326000613598, -0.09892352885154021)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4392035033230055, 0.9199918686937253, -0.09828574683226021)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.435719241379002, 0.91877273394179, -0.09562683499491853)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.434479824642845, 0.9186734776826665, -0.094681010632649)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.] (0.9267209955763123, 0.7178693022449502, 0.2928001784447877)\n",
      "[0 0 0 1 1 0 0 1] (0.936694443603544, 0.7157116486595606, 0.2851892354545923)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4392977960615998, 0.9191451553190463, -0.09835770355734375)\n",
      "[0 0 1 1 0 0 0 0] (1.1844301679616784, 0.839748096997316, 0.09613701704664446)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4362287823585755, 0.9188836694205945, -0.09601567617964357)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.441422607830682, 0.9193796870780269, -0.09997919105045794)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4377215413340565, 0.9204177950331649, -0.09715483120701895)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.441327926566456, 0.9199602582116035, -0.0999069378334867)\n",
      "\n",
      "\n",
      "[0. 1. 1. 1. 0. 1. 1. 1.] (0.22641051689921, 0.3051442904796513, 0.8272214853082396)\n",
      "[0. 1. 1. 1. 0. 1. 1. 1.] (0.22541114410834964, 0.3034424527131785, 0.8279841272066506)\n",
      "[0. 1. 0. 0. 1. 1. 1. 1.] (0.29112054486881095, 0.35809482117248076, 0.7778399341710762)\n",
      "[1. 0. 1. 0. 1. 0. 0. 1.] (0.4732240756928881, 0.4737777161579458, 0.6388729903788153)\n",
      "[1 0 1 0 0 0 0 1] (0.4868133499546413, 0.48020187337693804, 0.6285027361395659)\n",
      "[1. 0. 1. 1. 0. 0. 0. 0.] (0.6476968180013252, 0.5872176562742248, 0.5057292579979138)\n",
      "[1. 0. 1. 0. 1. 0. 0. 0.] (0.6561289960075913, 0.5941895016957365, 0.4992944898100572)\n",
      "[0. 0. 1. 1. 0. 0. 0. 1.] (0.6779614296292679, 0.5804115442102713, 0.48263371139339484)\n",
      "[0. 0. 1. 0. 1. 0. 0. 1.] (0.7041526317537034, 0.5913343912306203, 0.4626466672267754)\n",
      "[1 0 1 0 0 0 0 0] (0.7171522217616163, 0.6230709939437986, 0.45272641315055284)\n",
      "[0. 0. 0. 0. 0. 0. 0. 1.] (0.9267209955763123, 0.7178693022449502, 0.2928001784447877)\n",
      "[0 0 0 1 1 0 0 1] (0.936694443603544, 0.7157116486595606, 0.2851892354545923)\n",
      "[0 0 1 1 0 0 0 0] (1.1844301679616784, 0.839748096997316, 0.09613701704664446)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4405712399572432, 0.920139908338928, -0.09932949474375108)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4328434204182658, 0.9181745712363589, -0.09343223696599123)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4471423212293224, 0.9219233918148416, -0.10434402179690072)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4415493379841424, 0.9205797299732853, -0.1000759014329149)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4385039279491165, 0.9199715750246572, -0.09775188649895572)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.438099815477537, 0.9217281760328034, -0.09744349997361157)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.438434444673842, 0.9187769824905118, -0.09769886238478342)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4418944235664481, 0.921688587439236, -0.10033924332696142)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4458816132179793, 0.9222768206499745, -0.10338194962532898)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.437228863757465, 0.9198834331495996, -0.0967788588313927)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4460171532124613, 0.9214992755743584, -0.10348538297837573)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4399026460098243, 0.9197538433347752, -0.09881927697317638)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.44375087852088, 0.9218788434926402, -0.10175594222422024)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4361480111400766, 0.9204207073395393, -0.09595403800420366)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4396695159198005, 0.9194945324146747, -0.09864137061424971)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4362287823585755, 0.9188836694205945, -0.09601567617964357)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4362898690646033, 0.9190288269832233, -0.0960622926994037)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4394634874273307, 0.91995272557283, -0.09848414604093647)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4458421174141483, 0.921737415936481, -0.10335180956639567)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4399014215660422, 0.9207210545875437, -0.0988183425749829)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4406082491839687, 0.9198206923343868, -0.09935773724463437)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4377215413340565, 0.9204177950331649, -0.09715483120701895)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4429673664072293, 0.9220964011496976, -0.10115802804119745)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428833677380493, 0.9209698583760342, -0.10109392693186825)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4385227336252921, 0.9198880006458215, -0.09776623749661195)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4392035033230055, 0.9199918686937253, -0.09828574683226021)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4392977960615998, 0.9191451553190463, -0.09835770355734375)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4399015071634687, 0.9201021180194585, -0.09881840789613672)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4460301024238158, 0.9198722089348967, -0.10349526478746696)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4419231650503923, 0.9206766413756229, -0.10036117654355348)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4406770372782924, 0.9204373891159099, -0.09941023085194778)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4407779793301174, 0.9196341290096379, -0.0994872618044984)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4434027864929215, 0.9217801889182181, -0.10149030604975984)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4423241684480241, 0.920944765311058, -0.10066719047072481)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4418121227120375, 0.9202075620706536, -0.10027643785494678)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4453011815207586, 0.9218108988807754, -0.10293901027825614)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4419398910218981, 0.9213501739031736, -0.10037394047587056)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.445390839394401, 0.9210977324246818, -0.10300743004271973)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.442673372085459, 0.9213147298551125, -0.10093367493720318)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428016174046128, 0.9209485862732442, -0.10103154157371375)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.442819356771872, 0.9205805714077206, -0.10104507884913971)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428251804607315, 0.9222238270821796, -0.10104952302569559)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4428752303352304, 0.9207403682090369, -0.10108771711267894)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4440078186512835, 0.9204225729418718, -0.1019520185138898)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4461402435093662, 0.9229841172542335, -0.1035793157115521)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4469847736010455, 0.9228556494569604, -0.10422379396658754)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.4489651398053627, 0.9226571629784687, -0.10573505208309975)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop Terminated Because Of Continuous Similar Results\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "patterns = []\n",
    "best_pattern, best_accuracy = PSO(accuracies, patterns, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96ba8bf5-e02b-45aa-ae3e-25958464b4af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Pattern: [0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "Best Accuracy: (1.4489651398053627, 0.9226571629784687, -0.10573505208309975)\n",
      "Column Names Which Gave Best Accuracy Are:\n",
      "\n",
      "\n",
      "HouseAge\n",
      "AveOccup\n",
      "\n",
      "Best Accuracy Is: (1.4489651398053627, 0.9226571629784687, -0.10573505208309975)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Pattern:\", best_pattern)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "columns = df.columns[:-1]  # 'PRICE' 열을 제외한 열 이름들\n",
    "print(\"Column Names Which Gave Best Accuracy Are:\")\n",
    "print(\"\\n\")\n",
    "for i in range(len(best_pattern)):\n",
    "    if best_pattern[i] == 1:\n",
    "        print(columns[i])\n",
    "print(\"\\nBest Accuracy Is:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911ab32",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "745f26f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x , y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "959c2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(input_shape):\n",
    "    \"\"\" CNN 모델을 빌드하고 컴파일하는 함수 \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 1), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fffecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1032/1032 [==============================] - 3s 2ms/step - loss: 77.8107 - mean_absolute_error: 2.5041 - mean_squared_error: 77.8107\n",
      "Epoch 2/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 25.4583 - mean_absolute_error: 2.0310 - mean_squared_error: 25.4583\n",
      "Epoch 3/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 293.3281 - mean_absolute_error: 3.1339 - mean_squared_error: 293.3281\n",
      "Epoch 4/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 0.7391 - mean_absolute_error: 0.6565 - mean_squared_error: 0.7391\n",
      "Epoch 5/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 2.1727 - mean_absolute_error: 0.8160 - mean_squared_error: 2.1727\n",
      "Epoch 6/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 1.2328 - mean_absolute_error: 0.7420 - mean_squared_error: 1.2328\n",
      "Epoch 7/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 4.1651 - mean_absolute_error: 1.0828 - mean_squared_error: 4.1651\n",
      "Epoch 8/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 11.5894 - mean_absolute_error: 1.1512 - mean_squared_error: 11.5894\n",
      "Epoch 9/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 0.8032 - mean_absolute_error: 0.6700 - mean_squared_error: 0.8032\n",
      "Epoch 10/10\n",
      "1032/1032 [==============================] - 2s 2ms/step - loss: 3.6041 - mean_absolute_error: 1.1140 - mean_squared_error: 3.6041\n",
      "129/129 [==============================] - 0s 997us/step\n"
     ]
    }
   ],
   "source": [
    "feature_count = x.shape[1]\n",
    "x = np.array(x).reshape((-1, feature_count, 1, 1))  # (samples, features, 1, 1) 형태로 재구성\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "input_shape = (feature_count, 1, 1)\n",
    "model = build_cnn(input_shape)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=16, verbose=1)\n",
    "    \n",
    "prediction = model.predict(X_test)\n",
    "mse = mean_squared_error(Y_test, prediction)\n",
    "mae = mean_absolute_error(Y_test, prediction)\n",
    "r2 = r2_score(Y_test, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6b447d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1822150982691513\n",
      "0.8770011573400597\n",
      "0.09782738221454845\n"
     ]
    }
   ],
   "source": [
    "print(mse)\n",
    "print(mae)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ef0cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61ca23f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "def build_cnn(input_shape):\n",
    "    \"\"\" CNN 모델을 빌드하고 컴파일하는 함수 \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(1, 1), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error', 'mean_squared_error'])\n",
    "    return model\n",
    "\n",
    "def FitnessFunction(ffX, ffY):\n",
    "    \"\"\" 주어진 데이터로 CNN 모델을 훈련시키고 피트니스 값을 반환하는 함수 \"\"\"\n",
    "    if ffX.empty or ffY.empty or len(ffX) != len(ffY):\n",
    "        return float('inf'), float('inf'), float('-inf')\n",
    "    \n",
    "    # CNN 입력을 위해 데이터 재구성\n",
    "    feature_count = ffX.shape[1]\n",
    "    ffX = np.array(ffX).reshape((-1, feature_count, 1, 1))  # (samples, features, 1, 1) 형태로 재구성\n",
    "    ffX_train, ffX_test, ffY_train, ffY_test = train_test_split(ffX, ffY, test_size=0.2, random_state=42)\n",
    "    \n",
    "    input_shape = (feature_count, 1, 1)\n",
    "    model = build_cnn(input_shape)\n",
    "    model.fit(ffX_train, ffY_train, epochs=10, batch_size=16, verbose=0)\n",
    "    \n",
    "    prediction = model.predict(ffX_test)\n",
    "    mse = mean_squared_error(ffY_test, prediction)\n",
    "    mae = mean_absolute_error(ffY_test, prediction)\n",
    "    r2 = r2_score(ffY_test, prediction)\n",
    "\n",
    "    return mse, mae, r2\n",
    "\n",
    "def population_initialization_display(selected):\n",
    "    \"\"\" 선택된 패턴을 출력하는 함수 \"\"\"\n",
    "    print(\"Pattern:\", selected)\n",
    "\n",
    "def population_initialization(df):\n",
    "    \"\"\" 초기 개체군을 생성하고 피트니스 값을 계산하는 함수 \"\"\"\n",
    "    sX = df.drop('PRICE', axis=1)\n",
    "    sY = df['PRICE']\n",
    "    \n",
    "    columns = sX.columns\n",
    "    selected = np.random.randint(2, size=len(columns))\n",
    "    \n",
    "    modified_dataset = pd.DataFrame()\n",
    "    for i in range(len(columns)):\n",
    "        if selected[i] == 1:\n",
    "            modified_dataset[columns[i]] = sX[columns[i]]\n",
    "    \n",
    "    modified_dataset = modified_dataset.dropna()  # 결측치 제거로 데이터 길이 맞춤\n",
    "    \n",
    "    # modified_dataset과 sY의 길이가 일치하는지 확인\n",
    "    if len(modified_dataset) != len(sY):\n",
    "        return float('inf'), selected\n",
    "    \n",
    "    population_initialization_display(selected)\n",
    "    return FitnessFunction(modified_dataset, sY), selected\n",
    "\n",
    "def generation(df, population_size):\n",
    "    \"\"\" 초기 개체군을 생성하는 함수 \"\"\"\n",
    "    accuracies = []\n",
    "    patterns = []\n",
    "    for i in range(population_size):\n",
    "        acc, pattern = population_initialization(df)\n",
    "        accuracies.append(acc)\n",
    "        patterns.append(pattern)\n",
    "    return accuracies, patterns\n",
    "\n",
    "def Sorting(accuracies, patterns):\n",
    "    \"\"\" 개체군을 피트니스 값에 따라 정렬하는 함수 \"\"\"\n",
    "    combined = list(zip(accuracies, patterns))\n",
    "    combined.sort(key=lambda x: x[0])  # accuracies를 기준으로 정렬\n",
    "    accuracies[:], patterns[:] = zip(*combined)  # 분리하여 다시 리스트로 만듦\n",
    "\n",
    "def velocity(array, updated, Gbest):\n",
    "    \"\"\" 입자의 속도를 업데이트하는 함수 \"\"\"\n",
    "    c1 = 0.3\n",
    "    c2 = 0.7\n",
    "    r1 = np.random.random()\n",
    "    r2 = np.random.random()\n",
    "\n",
    "    vel = c1 * r1 * (updated - array) + c2 * r2 * (Gbest - array)\n",
    "    updated = updated + vel\n",
    "    return updated\n",
    "\n",
    "def PSO(accuracies, patterns, df, population_size=60):\n",
    "    \"\"\" PSO 알고리즘을 실행하여 최적의 패턴과 정확도를 찾는 함수 \"\"\"\n",
    "    accuracies, patterns = generation(df, population_size)\n",
    "    print(\"Highest Accuracy Patterns And Their Accuracies\\n\\n\")\n",
    "    \n",
    "    terminate_accuracy = None\n",
    "    best_pattern = []\n",
    "    best_accuracy = 0\n",
    "    \n",
    "    for _ in range(200): # Termination Criteria\n",
    "        print(\"\\n\")\n",
    "        for i in range(population_size):\n",
    "            print(f\"{patterns[i]} ({accuracies[i][0]:.3f}, {accuracies[i][1]:.3f}, {accuracies[i][2]:.3f})\")\n",
    "        \n",
    "        Sorting(accuracies, patterns)\n",
    "        \n",
    "        array = np.array(patterns)\n",
    "        updated = np.array(patterns)\n",
    "        gbest = np.array(patterns[-1])  # 마지막 개체 사용\n",
    "        updated = velocity(array, updated, gbest)\n",
    "        updated_accuracies = []\n",
    "        \n",
    "        maxlist = [max(row) for row in updated]\n",
    "        \n",
    "        for i in range(population_size):\n",
    "            updated[i] = updated[i] / maxlist[i]\n",
    "            updated[i] = [0 if val < 0.5 else 1 for val in updated[i]]\n",
    "        \n",
    "        sX = df.drop('PRICE', axis=1)\n",
    "        sY = df['PRICE']\n",
    "        columns = df.columns\n",
    "\n",
    "        for i in range(population_size):\n",
    "            modified_dataset = pd.DataFrame()\n",
    "            for j in range(8):  # 8개의 열에 맞게 수정\n",
    "                if updated[i][j] == 1:\n",
    "                    modified_dataset[columns[j]] = sX[columns[j]]\n",
    "            if len(modified_dataset) == len(sY):\n",
    "                updated_accuracies.append(FitnessFunction(modified_dataset, sY))\n",
    "            else:\n",
    "                updated_accuracies.append((float('inf'), float('inf'), float('-inf')))\n",
    "\n",
    "        pbest = []\n",
    "        pbest_accuracies = []\n",
    "\n",
    "        for i in range(population_size):\n",
    "            if accuracies[i] <= updated_accuracies[i]:\n",
    "                pbest.append(updated[i]) \n",
    "                pbest_accuracies.append(updated_accuracies[i])\n",
    "            else:\n",
    "                pbest.append(patterns[i]) \n",
    "                pbest_accuracies.append(accuracies[i])\n",
    "\n",
    "        patterns = pbest\n",
    "        accuracies = pbest_accuracies\n",
    "        \n",
    "        if terminate_accuracy == accuracies[-1]:\n",
    "            print(\"Loop Terminated Because Of Continuous Similar Results\")\n",
    "            break\n",
    "        \n",
    "        if accuracies[-1][2] >= 0.8:\n",
    "            break\n",
    "            \n",
    "        terminate_accuracy = accuracies[-1]\n",
    "        \n",
    "    Sorting(accuracies, patterns)\n",
    "    best_pattern = patterns[-1]\n",
    "    best_accuracy = accuracies[-1]\n",
    "    \n",
    "    return best_pattern, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cafbd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b7c2c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern: [0 1 0 0 0 0 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-30 06:05:59.328911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8907\n",
      "2024-06-30 06:06:00.608123: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4239271e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-30 06:06:00.608164: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): CUDA GPU, Compute Capability 8.0\n",
      "2024-06-30 06:06:00.608175: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): CUDA GPU, Compute Capability 8.0\n",
      "2024-06-30 06:06:00.614755: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-30 06:06:00.722962: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 1 1 0 0 1 1 1]\n",
      "129/129 [==============================] - 0s 970us/step\n",
      "Pattern: [1 1 1 1 0 0 1 0]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 1 1 1 1 0 1 0]\n",
      "129/129 [==============================] - 0s 949us/step\n",
      "Pattern: [1 1 0 0 0 0 0 1]\n",
      "129/129 [==============================] - 0s 953us/step\n",
      "Pattern: [1 1 0 0 0 0 1 1]\n",
      "129/129 [==============================] - 0s 978us/step\n",
      "Pattern: [0 1 1 0 1 0 0 1]\n",
      "129/129 [==============================] - 0s 997us/step\n",
      "Pattern: [0 1 1 1 0 0 1 1]\n",
      "129/129 [==============================] - 0s 989us/step\n",
      "Pattern: [1 0 1 1 0 0 1 1]\n",
      "129/129 [==============================] - 0s 952us/step\n",
      "Pattern: [1 1 0 1 0 0 0 0]\n",
      "129/129 [==============================] - 0s 977us/step\n",
      "Pattern: [1 0 0 0 0 1 1 0]\n",
      "129/129 [==============================] - 0s 954us/step\n",
      "Pattern: [0 1 0 0 0 0 0 1]\n",
      "129/129 [==============================] - 0s 996us/step\n",
      "Pattern: [0 0 1 1 0 1 0 0]\n",
      "129/129 [==============================] - 0s 963us/step\n",
      "Pattern: [0 1 0 0 0 0 1 0]\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "Pattern: [0 0 1 0 1 1 0 0]\n",
      "129/129 [==============================] - 0s 932us/step\n",
      "Pattern: [0 0 1 1 0 1 1 1]\n",
      "129/129 [==============================] - 0s 981us/step\n",
      "Pattern: [0 1 1 1 1 1 1 1]\n",
      "129/129 [==============================] - 1s 956us/step\n",
      "Pattern: [1 0 1 1 1 0 1 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 1 1 1 1 0 0 1]\n",
      "129/129 [==============================] - 0s 988us/step\n",
      "Pattern: [0 0 1 0 0 0 0 0]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [1 0 0 1 1 1 1 0]\n",
      "129/129 [==============================] - 0s 954us/step\n",
      "Pattern: [1 1 0 0 0 1 1 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 0 1 1 0 0 1 0]\n",
      "129/129 [==============================] - 0s 981us/step\n",
      "Pattern: [1 0 1 1 1 0 1 0]\n",
      "129/129 [==============================] - 0s 991us/step\n",
      "Pattern: [0 1 0 1 1 1 0 0]\n",
      "129/129 [==============================] - 0s 994us/step\n",
      "Pattern: [0 1 1 1 1 0 0 1]\n",
      "129/129 [==============================] - 0s 930us/step\n",
      "Pattern: [0 1 1 1 1 0 1 1]\n",
      "129/129 [==============================] - 0s 950us/step\n",
      "Pattern: [0 0 0 0 1 1 0 1]\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "Pattern: [0 1 0 1 0 1 0 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [1 0 0 1 0 0 1 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 0 0 0 1 1 1 1]\n",
      "129/129 [==============================] - 0s 940us/step\n",
      "Pattern: [0 1 0 0 0 1 0 0]\n",
      "129/129 [==============================] - 0s 961us/step\n",
      "Pattern: [0 1 1 1 0 0 1 0]\n",
      "129/129 [==============================] - 0s 960us/step\n",
      "Pattern: [1 0 1 0 0 0 0 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [1 1 0 1 0 0 1 0]\n",
      "129/129 [==============================] - 0s 989us/step\n",
      "Pattern: [1 1 0 0 1 0 0 1]\n",
      "129/129 [==============================] - 0s 953us/step\n",
      "Pattern: [0 0 0 1 1 0 1 0]\n",
      "129/129 [==============================] - 0s 982us/step\n",
      "Pattern: [0 1 1 1 1 0 0 1]\n",
      "129/129 [==============================] - 0s 994us/step\n",
      "Pattern: [0 1 1 1 1 0 1 0]\n",
      "129/129 [==============================] - 0s 973us/step\n",
      "Pattern: [0 1 1 1 1 1 0 0]\n",
      "129/129 [==============================] - 0s 952us/step\n",
      "Pattern: [1 1 1 1 0 0 0 1]\n",
      "129/129 [==============================] - 0s 985us/step\n",
      "Pattern: [1 1 1 0 0 0 1 0]\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "Pattern: [0 1 1 0 1 1 0 0]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 1 1 0 1 1 0 1]\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "Pattern: [1 0 0 0 0 0 0 0]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 0 1 1 1 1 0 0]\n",
      "129/129 [==============================] - 0s 957us/step\n",
      "Pattern: [1 0 0 0 0 1 1 1]\n",
      "129/129 [==============================] - 0s 954us/step\n",
      "Pattern: [0 1 0 1 1 0 1 0]\n",
      "129/129 [==============================] - 0s 977us/step\n",
      "Pattern: [0 1 1 1 0 0 1 1]\n",
      "129/129 [==============================] - 0s 990us/step\n",
      "Pattern: [0 0 1 0 0 1 0 0]\n",
      "129/129 [==============================] - 0s 953us/step\n",
      "Pattern: [0 1 1 1 1 0 0 1]\n",
      "129/129 [==============================] - 0s 960us/step\n",
      "Pattern: [1 0 1 1 0 0 1 1]\n",
      "129/129 [==============================] - 0s 970us/step\n",
      "Pattern: [0 0 1 1 1 0 1 1]\n",
      "129/129 [==============================] - 0s 939us/step\n",
      "Pattern: [1 1 0 1 1 0 1 0]\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "Pattern: [0 1 0 1 0 1 0 0]\n",
      "129/129 [==============================] - 0s 946us/step\n",
      "Pattern: [0 0 1 0 1 1 0 0]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [1 1 1 1 0 0 0 1]\n",
      "129/129 [==============================] - 0s 995us/step\n",
      "Pattern: [1 1 1 1 0 0 0 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [0 1 0 1 1 1 1 1]\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Pattern: [1 1 1 0 1 1 0 1]\n",
      "129/129 [==============================] - 0s 996us/step\n",
      "Highest Accuracy Patterns And Their Accuracies\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[0 1 0 0 0 0 1 1] (1.509, 0.873, -0.152)\n",
      "[0 1 1 0 0 1 1 1] (0.942, 0.791, 0.281)\n",
      "[1 1 1 1 0 0 1 0] (0.577, 0.562, 0.559)\n",
      "[0 1 1 1 1 0 1 0] (1.219, 0.885, 0.070)\n",
      "[1 1 0 0 0 0 0 1] (0.668, 0.641, 0.491)\n",
      "[1 1 0 0 0 0 1 1] (0.626, 0.556, 0.523)\n",
      "[0 1 1 0 1 0 0 1] (1.185, 0.845, 0.096)\n",
      "[0 1 1 1 0 0 1 1] (1.012, 0.797, 0.227)\n",
      "[1 0 1 1 0 0 1 1] (0.661, 0.619, 0.495)\n",
      "[1 1 0 1 0 0 0 0] (0.680, 0.586, 0.481)\n",
      "[1 0 0 0 0 1 1 0] (0.610, 0.559, 0.535)\n",
      "[0 1 0 0 0 0 0 1] (1.301, 0.916, 0.007)\n",
      "[0 0 1 1 0 1 0 0] (0.943, 0.750, 0.280)\n",
      "[0 1 0 0 0 0 1 0] (1.314, 0.882, -0.003)\n",
      "[0 0 1 0 1 1 0 0] (1.509, 0.914, -0.152)\n",
      "[0 0 1 1 0 1 1 1] (0.884, 0.721, 0.326)\n",
      "[0 1 1 1 1 1 1 1] (3.053, 1.398, -1.330)\n",
      "[1 0 1 1 1 0 1 1] (0.686, 0.608, 0.476)\n",
      "[0 1 1 1 1 0 0 1] (1.124, 0.840, 0.142)\n",
      "[0 0 1 0 0 0 0 0] (1.116, 0.814, 0.148)\n",
      "[1 0 0 1 1 1 1 0] (1.392, 0.835, -0.063)\n",
      "[1 1 0 0 0 1 1 1] (0.538, 0.571, 0.590)\n",
      "[0 0 1 1 0 0 1 0] (1.058, 0.785, 0.192)\n",
      "[1 0 1 1 1 0 1 0] (1.046, 0.849, 0.202)\n",
      "[0 1 0 1 1 1 0 0] (1.413, 0.896, -0.078)\n",
      "[0 1 1 1 1 0 0 1] (1.619, 0.971, -0.236)\n",
      "[0 1 1 1 1 0 1 1] (1.189, 0.909, 0.093)\n",
      "[0 0 0 0 1 1 0 1] (7.398, 2.337, -4.645)\n",
      "[0 1 0 1 0 1 0 1] (1.270, 0.841, 0.031)\n",
      "[1 0 0 1 0 0 1 1] (0.714, 0.588, 0.455)\n",
      "[0 0 0 0 1 1 1 1] (1.369, 0.898, -0.045)\n",
      "[0 1 0 0 0 1 0 0] (1.184, 0.835, 0.096)\n",
      "[0 1 1 1 0 0 1 0] (1.021, 0.762, 0.220)\n",
      "[1 0 1 0 0 0 0 1] (0.646, 0.610, 0.507)\n",
      "[1 1 0 1 0 0 1 0] (0.624, 0.594, 0.524)\n",
      "[1 1 0 0 1 0 0 1] (0.660, 0.602, 0.496)\n",
      "[0 0 0 1 1 0 1 0] (2.057, 1.210, -0.570)\n",
      "[0 1 1 1 1 0 0 1] (1.147, 0.858, 0.125)\n",
      "[0 1 1 1 1 0 1 0] (2.743, 1.246, -1.093)\n",
      "[0 1 1 1 1 1 0 0] (18.141, 3.704, -12.843)\n",
      "[1 1 1 1 0 0 0 1] (0.636, 0.549, 0.515)\n",
      "[1 1 1 0 0 0 1 0] (0.613, 0.600, 0.532)\n",
      "[0 1 1 0 1 1 0 0] (1.685, 1.081, -0.286)\n",
      "[0 1 1 0 1 1 0 1] (5.808, 1.967, -3.432)\n",
      "[1 0 0 0 0 0 0 0] (0.702, 0.616, 0.464)\n",
      "[0 0 1 1 1 1 0 0] (1.257, 0.844, 0.041)\n",
      "[1 0 0 0 0 1 1 1] (0.534, 0.537, 0.592)\n",
      "[0 1 0 1 1 0 1 0] (2.231, 1.266, -0.702)\n",
      "[0 1 1 1 0 0 1 1] (1.071, 0.852, 0.183)\n",
      "[0 0 1 0 0 1 0 0] (1.056, 0.795, 0.195)\n",
      "[0 1 1 1 1 0 0 1] (1.304, 0.950, 0.005)\n",
      "[1 0 1 1 0 0 1 1] (0.629, 0.577, 0.520)\n",
      "[0 0 1 1 1 0 1 1] (1.661, 1.115, -0.268)\n",
      "[1 1 0 1 1 0 1 0] (2.258, 1.169, -0.723)\n",
      "[0 1 0 1 0 1 0 0] (1.210, 0.829, 0.077)\n",
      "[0 0 1 0 1 1 0 0] (1.284, 0.858, 0.020)\n",
      "[1 1 1 1 0 0 0 1] (0.579, 0.548, 0.558)\n",
      "[1 1 1 1 0 0 0 1] (0.624, 0.551, 0.524)\n",
      "[0 1 0 1 1 1 1 1] (1.848, 1.156, -0.411)\n",
      "[1 1 1 0 1 1 0 1] (0.644, 0.606, 0.508)\n",
      "129/129 [==============================] - 0s 950us/step\n",
      "129/129 [==============================] - 0s 937us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 1s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 981us/step\n",
      "129/129 [==============================] - 0s 975us/step\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "129/129 [==============================] - 0s 988us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 978us/step\n",
      "129/129 [==============================] - 0s 963us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 947us/step\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "129/129 [==============================] - 0s 970us/step\n",
      "129/129 [==============================] - 0s 966us/step\n",
      "129/129 [==============================] - 0s 968us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 969us/step\n",
      "129/129 [==============================] - 0s 991us/step\n",
      "129/129 [==============================] - 0s 953us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 981us/step\n",
      "129/129 [==============================] - 0s 923us/step\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "129/129 [==============================] - 0s 943us/step\n",
      "129/129 [==============================] - 0s 951us/step\n",
      "129/129 [==============================] - 0s 938us/step\n",
      "129/129 [==============================] - 0s 951us/step\n",
      "129/129 [==============================] - 0s 968us/step\n",
      "129/129 [==============================] - 1s 951us/step\n",
      "129/129 [==============================] - 0s 935us/step\n",
      "129/129 [==============================] - 0s 958us/step\n",
      "129/129 [==============================] - 0s 970us/step\n",
      "129/129 [==============================] - 0s 957us/step\n",
      "129/129 [==============================] - 0s 948us/step\n",
      "129/129 [==============================] - 0s 911us/step\n",
      "129/129 [==============================] - 0s 973us/step\n",
      "129/129 [==============================] - 0s 968us/step\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "129/129 [==============================] - 0s 930us/step\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "129/129 [==============================] - 0s 914us/step\n",
      "129/129 [==============================] - 0s 961us/step\n",
      "129/129 [==============================] - 0s 948us/step\n",
      "129/129 [==============================] - 0s 950us/step\n",
      "129/129 [==============================] - 0s 956us/step\n",
      "129/129 [==============================] - 0s 968us/step\n",
      "129/129 [==============================] - 0s 943us/step\n",
      "129/129 [==============================] - 0s 982us/step\n",
      "129/129 [==============================] - 0s 961us/step\n",
      "129/129 [==============================] - 0s 925us/step\n",
      "129/129 [==============================] - 0s 947us/step\n",
      "129/129 [==============================] - 0s 988us/step\n",
      "129/129 [==============================] - 0s 962us/step\n",
      "129/129 [==============================] - 0s 976us/step\n",
      "129/129 [==============================] - 0s 961us/step\n",
      "\n",
      "\n",
      "[1. 0. 0. 0. 0. 1. 1. 1.] (0.564, 0.565, 0.570)\n",
      "[1. 1. 0. 0. 0. 1. 1. 1.] (0.636, 0.574, 0.515)\n",
      "[1. 1. 1. 1. 0. 0. 1. 0.] (0.585, 0.564, 0.553)\n",
      "[1. 1. 1. 1. 0. 0. 0. 1.] (0.597, 0.552, 0.545)\n",
      "[1 0 0 0 0 1 1 0] (0.610, 0.559, 0.535)\n",
      "[1 1 1 0 0 0 1 0] (0.613, 0.600, 0.532)\n",
      "[1. 1. 0. 1. 0. 0. 1. 0.] (0.637, 0.571, 0.514)\n",
      "[1 1 1 1 0 0 0 1] (0.624, 0.551, 0.524)\n",
      "[1. 1. 0. 0. 0. 0. 1. 1.] (0.642, 0.627, 0.510)\n",
      "[1. 0. 1. 1. 0. 0. 1. 1.] (0.637, 0.596, 0.514)\n",
      "[1 1 1 1 0 0 0 1] (0.636, 0.549, 0.515)\n",
      "[1. 1. 1. 0. 1. 1. 0. 1.] (1.071, 0.746, 0.183)\n",
      "[1. 0. 1. 0. 0. 0. 0. 1.] (0.683, 0.569, 0.479)\n",
      "[1. 1. 0. 0. 1. 0. 0. 1.] (0.687, 0.606, 0.476)\n",
      "[1 0 1 1 0 0 1 1] (0.661, 0.619, 0.495)\n",
      "[1 1 0 0 0 0 0 1] (0.668, 0.641, 0.491)\n",
      "[1 1 0 1 0 0 0 0] (0.680, 0.586, 0.481)\n",
      "[1. 0. 1. 1. 1. 0. 1. 1.] (0.723, 0.685, 0.448)\n",
      "[1 0 0 0 0 0 0 0] (0.702, 0.616, 0.464)\n",
      "[1 0 0 1 0 0 1 1] (0.714, 0.588, 0.455)\n",
      "[0. 0. 1. 1. 0. 1. 1. 1.] (1.090, 0.797, 0.168)\n",
      "[0. 1. 1. 0. 0. 1. 1. 1.] (1.068, 0.768, 0.185)\n",
      "[0. 0. 1. 1. 0. 1. 0. 0.] (0.968, 0.752, 0.262)\n",
      "[0. 1. 1. 1. 0. 0. 1. 1.] (1.021, 0.776, 0.221)\n",
      "[0 1 1 1 0 0 1 0] (1.021, 0.762, 0.220)\n",
      "[1. 0. 1. 1. 1. 0. 1. 0.] (1.476, 1.006, -0.126)\n",
      "[0 0 1 0 0 1 0 0] (1.056, 0.795, 0.195)\n",
      "[0. 0. 1. 1. 0. 0. 1. 0.] (1.160, 0.842, 0.114)\n",
      "[0 1 1 1 0 0 1 1] (1.071, 0.852, 0.183)\n",
      "[0. 0. 1. 0. 0. 0. 0. 0.] (1.137, 0.853, 0.132)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (1.365, 0.982, -0.042)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (1.375, 0.977, -0.049)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.302, 0.863, 0.006)\n",
      "[0. 1. 1. 0. 1. 0. 0. 1.] (1.382, 0.978, -0.055)\n",
      "[0. 1. 1. 1. 1. 0. 1. 1.] (1.297, 0.952, 0.010)\n",
      "[0 1 0 1 0 1 0 0] (1.210, 0.829, 0.077)\n",
      "[0. 1. 1. 1. 1. 0. 1. 0.] (1.384, 0.910, -0.056)\n",
      "[0. 0. 1. 1. 1. 1. 0. 0.] (1.288, 0.905, 0.017)\n",
      "[0 1 0 1 0 1 0 1] (1.270, 0.841, 0.031)\n",
      "[0. 0. 1. 0. 1. 1. 0. 0.] (82.992, 7.110, -62.333)\n",
      "[0. 1. 0. 0. 0. 0. 0. 1.] (1.336, 0.869, -0.019)\n",
      "[0 1 1 1 1 0 0 1] (1.304, 0.950, 0.005)\n",
      "[0 1 0 0 0 0 1 0] (1.314, 0.882, -0.003)\n",
      "[0. 0. 0. 0. 1. 1. 1. 1.] (9.306, 2.818, -6.101)\n",
      "[1 0 0 1 1 1 1 0] (1.392, 0.835, -0.063)\n",
      "[0 1 0 1 1 1 0 0] (1.413, 0.896, -0.078)\n",
      "[0. 0. 1. 0. 1. 1. 0. 0.] (2.425, 1.167, -0.850)\n",
      "[0 1 0 0 0 0 1 1] (1.509, 0.873, -0.152)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (4.563, 1.555, -2.482)\n",
      "[0. 0. 1. 1. 1. 0. 1. 1.] (2.223, 1.241, -0.697)\n",
      "[0 1 1 0 1 1 0 0] (1.685, 1.081, -0.286)\n",
      "[0 1 0 1 1 1 1 1] (1.848, 1.156, -0.411)\n",
      "[0 0 0 1 1 0 1 0] (2.057, 1.210, -0.570)\n",
      "[0 1 0 1 1 0 1 0] (2.231, 1.266, -0.702)\n",
      "[1 1 0 1 1 0 1 0] (2.258, 1.169, -0.723)\n",
      "[0 1 1 1 1 0 1 0] (2.743, 1.246, -1.093)\n",
      "[0 1 1 1 1 1 1 1] (3.053, 1.398, -1.330)\n",
      "[0 1 1 0 1 1 0 1] (5.808, 1.967, -3.432)\n",
      "[0 0 0 0 1 1 0 1] (7.398, 2.337, -4.645)\n",
      "[0 1 1 1 1 1 0 0] (18.141, 3.704, -12.843)\n",
      "129/129 [==============================] - 0s 966us/step\n",
      "129/129 [==============================] - 0s 974us/step\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "129/129 [==============================] - 0s 974us/step\n",
      "129/129 [==============================] - 0s 956us/step\n",
      "129/129 [==============================] - 0s 982us/step\n",
      "129/129 [==============================] - 0s 981us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 986us/step\n",
      "129/129 [==============================] - 0s 966us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 991us/step\n",
      "129/129 [==============================] - 0s 985us/step\n",
      "129/129 [==============================] - 0s 985us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 966us/step\n",
      "129/129 [==============================] - 0s 979us/step\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "129/129 [==============================] - 0s 905us/step\n",
      "129/129 [==============================] - 0s 981us/step\n",
      "129/129 [==============================] - 0s 974us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 948us/step\n",
      "129/129 [==============================] - 0s 965us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 956us/step\n",
      "129/129 [==============================] - 0s 975us/step\n",
      "129/129 [==============================] - 0s 985us/step\n",
      "129/129 [==============================] - 0s 990us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 925us/step\n",
      "129/129 [==============================] - 0s 941us/step\n",
      "129/129 [==============================] - 0s 944us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 952us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 971us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 976us/step\n",
      "129/129 [==============================] - 0s 974us/step\n",
      "129/129 [==============================] - 0s 955us/step\n",
      "129/129 [==============================] - 0s 969us/step\n",
      "129/129 [==============================] - 0s 964us/step\n",
      "129/129 [==============================] - 0s 979us/step\n",
      "129/129 [==============================] - 0s 958us/step\n",
      "129/129 [==============================] - 0s 962us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 964us/step\n",
      "129/129 [==============================] - 0s 928us/step\n",
      "129/129 [==============================] - 0s 943us/step\n",
      "129/129 [==============================] - 0s 993us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 934us/step\n",
      "129/129 [==============================] - 0s 954us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 970us/step\n",
      "129/129 [==============================] - 0s 948us/step\n",
      "\n",
      "\n",
      "[1. 0. 0. 0. 0. 1. 1. 1.] (0.583, 0.596, 0.555)\n",
      "[1. 1. 1. 1. 0. 0. 1. 0.] (0.605, 0.599, 0.538)\n",
      "[1. 1. 1. 1. 0. 0. 0. 1.] (0.597, 0.552, 0.545)\n",
      "[1 0 0 0 0 1 1 0] (0.610, 0.559, 0.535)\n",
      "[1 1 1 0 0 0 1 0] (0.613, 0.600, 0.532)\n",
      "[1 1 1 1 0 0 0 1] (0.624, 0.551, 0.524)\n",
      "[1 1 1 1 0 0 0 1] (0.636, 0.549, 0.515)\n",
      "[1. 1. 0. 0. 0. 1. 1. 1.] (0.636, 0.574, 0.515)\n",
      "[1. 1. 1. 1. 1. 1. 1. 0.] (1.017, 0.734, 0.224)\n",
      "[1. 0. 1. 1. 0. 0. 1. 1.] (0.700, 0.680, 0.466)\n",
      "[1. 1. 1. 0. 1. 1. 1. 1.] (0.689, 0.655, 0.474)\n",
      "[1. 0. 1. 1. 0. 0. 1. 1.] (0.677, 0.632, 0.484)\n",
      "[1 1 0 0 0 0 0 1] (0.668, 0.641, 0.491)\n",
      "[1. 1. 1. 1. 1. 1. 0. 0.] (0.688, 0.612, 0.475)\n",
      "[1. 0. 1. 0. 0. 0. 0. 1.] (0.683, 0.569, 0.479)\n",
      "[1. 1. 0. 0. 1. 0. 0. 1.] (0.687, 0.606, 0.476)\n",
      "[1. 0. 1. 0. 1. 1. 0. 0.] (0.763, 0.622, 0.418)\n",
      "[1. 0. 1. 1. 1. 1. 1. 1.] (0.726, 0.623, 0.446)\n",
      "[1. 0. 1. 1. 1. 0. 1. 1.] (0.738, 0.676, 0.437)\n",
      "[0. 0. 1. 1. 0. 1. 0. 0.] (0.968, 0.752, 0.262)\n",
      "[0. 1. 1. 1. 0. 0. 1. 1.] (1.021, 0.776, 0.221)\n",
      "[0 1 1 1 0 0 1 0] (1.021, 0.762, 0.220)\n",
      "[0. 0. 1. 0. 0. 1. 0. 0.] (1.121, 0.807, 0.145)\n",
      "[0. 1. 1. 0. 0. 1. 1. 1.] (1.068, 0.768, 0.185)\n",
      "[1. 1. 1. 0. 1. 1. 0. 1.] (1.071, 0.746, 0.183)\n",
      "[0 1 1 1 0 0 1 1] (1.071, 0.852, 0.183)\n",
      "[0. 0. 1. 1. 0. 1. 1. 1.] (1.090, 0.797, 0.168)\n",
      "[0. 0. 1. 0. 0. 0. 0. 0.] (1.148, 0.827, 0.124)\n",
      "[0. 0. 1. 1. 0. 0. 1. 0.] (1.160, 0.842, 0.114)\n",
      "[0. 1. 0. 1. 0. 1. 0. 0.] (1.349, 0.929, -0.030)\n",
      "[0 1 0 1 0 1 0 1] (1.270, 0.841, 0.031)\n",
      "[0. 0. 1. 1. 1. 1. 0. 0.] (1.288, 0.905, 0.017)\n",
      "[0. 1. 1. 1. 1. 0. 1. 1.] (1.331, 0.958, -0.015)\n",
      "[0. 1. 0. 0. 0. 1. 0. 0.] (1.302, 0.863, 0.006)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (2.965, 1.539, -1.263)\n",
      "[0. 1. 1. 0. 1. 1. 1. 0.] (2.137, 1.185, -0.630)\n",
      "[0. 1. 0. 0. 0. 0. 0. 1.] (1.336, 0.869, -0.019)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (1.365, 0.982, -0.042)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (1.375, 0.977, -0.049)\n",
      "[0. 1. 1. 0. 1. 0. 0. 1.] (13.981, 2.686, -9.669)\n",
      "[0. 1. 1. 1. 1. 0. 1. 0.] (1.389, 0.889, -0.060)\n",
      "[1 0 0 1 1 1 1 0] (1.392, 0.835, -0.063)\n",
      "[0. 1. 0. 1. 1. 1. 0. 0.] (1.547, 0.932, -0.180)\n",
      "[1. 0. 1. 1. 1. 0. 1. 0.] (11.368, 2.782, -7.675)\n",
      "[0 1 0 0 0 0 1 1] (1.509, 0.873, -0.152)\n",
      "[0 1 1 0 1 1 0 0] (1.685, 1.081, -0.286)\n",
      "[0 1 0 1 1 1 1 1] (1.848, 1.156, -0.411)\n",
      "[0 0 0 1 1 0 1 0] (2.057, 1.210, -0.570)\n",
      "[0. 0. 1. 1. 1. 0. 1. 1.] (2.223, 1.241, -0.697)\n",
      "[0 1 0 1 1 0 1 0] (2.231, 1.266, -0.702)\n",
      "[1 1 0 1 1 0 1 0] (2.258, 1.169, -0.723)\n",
      "[0. 0. 1. 0. 1. 1. 0. 0.] (8.168, 2.240, -5.233)\n",
      "[0 1 1 1 1 0 1 0] (2.743, 1.246, -1.093)\n",
      "[0 1 1 1 1 1 1 1] (3.053, 1.398, -1.330)\n",
      "[0. 1. 1. 1. 1. 0. 0. 1.] (4.563, 1.555, -2.482)\n",
      "[0 1 1 0 1 1 0 1] (5.808, 1.967, -3.432)\n",
      "[0 0 0 0 1 1 0 1] (7.398, 2.337, -4.645)\n",
      "[0. 0. 0. 0. 1. 1. 1. 1.] (9.306, 2.818, -6.101)\n",
      "[0 1 1 1 1 1 0 0] (18.141, 3.704, -12.843)\n",
      "[0. 0. 1. 0. 1. 1. 0. 0.] (82.992, 7.110, -62.333)\n",
      "129/129 [==============================] - 0s 950us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 939us/step\n",
      "129/129 [==============================] - 0s 942us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 988us/step\n",
      "129/129 [==============================] - 0s 950us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 964us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 948us/step\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 997us/step\n",
      "129/129 [==============================] - 0s 978us/step\n",
      "129/129 [==============================] - 0s 994us/step\n",
      "129/129 [==============================] - 0s 976us/step\n",
      "129/129 [==============================] - 0s 988us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 982us/step\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 967us/step\n",
      "129/129 [==============================] - 0s 996us/step\n",
      "129/129 [==============================] - 0s 948us/step\n",
      "129/129 [==============================] - 0s 965us/step\n",
      "129/129 [==============================] - 0s 992us/step\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "129/129 [==============================] - 0s 987us/step\n",
      "129/129 [==============================] - 0s 989us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 957us/step\n",
      "129/129 [==============================] - 0s 976us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 959us/step\n",
      "129/129 [==============================] - 0s 963us/step\n",
      "129/129 [==============================] - 0s 949us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 978us/step\n",
      "129/129 [==============================] - 0s 982us/step\n",
      "129/129 [==============================] - 0s 984us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 974us/step\n",
      "129/129 [==============================] - 0s 985us/step\n",
      "129/129 [==============================] - 0s 967us/step\n",
      "129/129 [==============================] - 0s 917us/step\n",
      "129/129 [==============================] - 0s 929us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "129/129 [==============================] - 0s 985us/step\n",
      "129/129 [==============================] - 0s 990us/step\n",
      "129/129 [==============================] - 0s 989us/step\n",
      "129/129 [==============================] - 0s 1ms/step\n",
      "Loop Terminated Because Of Continuous Similar Results\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "patterns = []\n",
    "best_pattern, best_accuracy = PSO(accuracies, patterns, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e246bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names Which Gave Best Accuracy Are:\n",
      "\n",
      "\n",
      "MedInc\n",
      "HouseAge\n",
      "AveRooms\n",
      "Population\n",
      "AveOccup\n",
      "Longitude\n",
      "\n",
      "Best Accuracy Is: (145.13440394575846, 7.96289221880068, -109.75504392574271)\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns[:-1]  # 'PRICE' 열을 제외한 열 이름들\n",
    "print(\"Column Names Which Gave Best Accuracy Are:\")\n",
    "print(\"\\n\")\n",
    "for i in range(len(best_pattern)):\n",
    "    if best_pattern[i] == 1:\n",
    "        print(columns[i])\n",
    "print(\"\\nBest Accuracy Is:\", best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (NGC 24.01 / TensorFlow 2.14) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
